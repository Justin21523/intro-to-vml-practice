{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 池化層 Pooling Layer\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "1. 理解池化層的作用（下採樣、平移不變性）\n",
    "2. 實作 Max Pooling 的前向和反向傳播\n",
    "3. 實作 Average Pooling\n",
    "4. 理解 Max Pooling 反向傳播的「路由」機制\n",
    "\n",
    "## 為什麼需要池化層？\n",
    "\n",
    "1. **下採樣**：減少特徵圖的空間大小，降低計算量和參數量\n",
    "2. **平移不變性**：即使物體稍微移動，池化後的特徵仍然相似\n",
    "3. **增大感受野**：每次池化後，後續卷積層的感受野翻倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Pooling Layer module loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：Max Pooling 前向傳播\n",
    "\n",
    "### 定義\n",
    "\n",
    "Max Pooling 在每個窗口內取最大值。\n",
    "\n",
    "- 輸入：$(N, C, H, W)$\n",
    "- 輸出：$(N, C, H', W')$\n",
    "\n",
    "其中：\n",
    "$$H' = \\frac{H - k_H}{S} + 1$$\n",
    "$$W' = \\frac{W - k_W}{S} + 1$$\n",
    "\n",
    "### 公式\n",
    "\n",
    "$$Y[n, c, i, j] = \\max_{p \\in [0, k_H), q \\in [0, k_W)} X[n, c, i \\cdot S + p, j \\cdot S + q]$$\n",
    "\n",
    "**重要**：需要記錄每個輸出位置對應的最大值來自哪個輸入位置，這在反向傳播時需要用到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d_forward_naive(X, pool_size, stride=None):\n",
    "    \"\"\"\n",
    "    Max Pooling 前向傳播（樸素版本）\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (N, C, H, W)\n",
    "    pool_size : int or tuple\n",
    "        池化窗口大小\n",
    "    stride : int or None\n",
    "        步長，預設等於 pool_size\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Y : np.ndarray, shape (N, C, H', W')\n",
    "    cache : dict\n",
    "        包含最大值位置，供反向傳播使用\n",
    "    \"\"\"\n",
    "    N, C, H, W = X.shape\n",
    "    \n",
    "    if isinstance(pool_size, int):\n",
    "        kH, kW = pool_size, pool_size\n",
    "    else:\n",
    "        kH, kW = pool_size\n",
    "    \n",
    "    if stride is None:\n",
    "        stride = kH\n",
    "    \n",
    "    H_out = (H - kH) // stride + 1\n",
    "    W_out = (W - kW) // stride + 1\n",
    "    \n",
    "    Y = np.zeros((N, C, H_out, W_out))\n",
    "    \n",
    "    # 記錄最大值的位置（用於反向傳播）\n",
    "    # 儲存每個輸出對應的輸入位置 (h_idx, w_idx)\n",
    "    max_indices = np.zeros((N, C, H_out, W_out, 2), dtype=int)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    \n",
    "                    # 取出窗口\n",
    "                    window = X[n, c, h_start:h_start+kH, w_start:w_start+kW]\n",
    "                    \n",
    "                    # 找最大值和其位置\n",
    "                    Y[n, c, i, j] = np.max(window)\n",
    "                    \n",
    "                    # 記錄最大值的相對位置\n",
    "                    max_pos = np.unravel_index(np.argmax(window), window.shape)\n",
    "                    max_indices[n, c, i, j, 0] = h_start + max_pos[0]\n",
    "                    max_indices[n, c, i, j, 1] = w_start + max_pos[1]\n",
    "    \n",
    "    cache = {'X_shape': X.shape, 'max_indices': max_indices, \n",
    "             'pool_size': (kH, kW), 'stride': stride}\n",
    "    \n",
    "    return Y, cache\n",
    "\n",
    "# 測試\n",
    "X = np.array([[[[1, 2, 3, 4],\n",
    "                [5, 6, 7, 8],\n",
    "                [9, 10, 11, 12],\n",
    "                [13, 14, 15, 16]]]], dtype=float)\n",
    "\n",
    "Y, cache = maxpool2d_forward_naive(X, pool_size=2, stride=2)\n",
    "\n",
    "print(\"輸入:\")\n",
    "print(X[0, 0])\n",
    "print(f\"\\n輸入形狀: {X.shape}\")\n",
    "print(f\"\\n輸出:\")\n",
    "print(Y[0, 0])\n",
    "print(f\"\\n輸出形狀: {Y.shape}\")\n",
    "print(\"\\n每個輸出對應的最大值位置 (h, w):\")\n",
    "print(cache['max_indices'][0, 0, :, :, :].reshape(2, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分：Max Pooling 反向傳播\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "Max 操作的梯度有一個重要特性：**梯度只流向最大值的位置**。\n",
    "\n",
    "對於每個輸出位置 $(i, j)$：\n",
    "- 找到對應的最大值輸入位置 $(h^*, w^*)$\n",
    "- 將 $dY[n, c, i, j]$ 加到 $dX[n, c, h^*, w^*]$\n",
    "- 其他位置的梯度為 0\n",
    "\n",
    "### 公式\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial X[n, c, h, w]} = \\sum_{(i, j) \\text{ s.t. } (h, w) \\in \\text{argmax}} \\frac{\\partial L}{\\partial Y[n, c, i, j]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d_backward_naive(dY, cache):\n",
    "    \"\"\"\n",
    "    Max Pooling 反向傳播\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dY : np.ndarray, shape (N, C, H_out, W_out)\n",
    "        對輸出的梯度\n",
    "    cache : dict\n",
    "        來自 forward 的快取\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dX : np.ndarray, shape (N, C, H, W)\n",
    "        對輸入的梯度\n",
    "    \"\"\"\n",
    "    X_shape = cache['X_shape']\n",
    "    max_indices = cache['max_indices']\n",
    "    \n",
    "    N, C, H, W = X_shape\n",
    "    _, _, H_out, W_out = dY.shape\n",
    "    \n",
    "    dX = np.zeros(X_shape)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    # 找到最大值的位置\n",
    "                    h_idx = max_indices[n, c, i, j, 0]\n",
    "                    w_idx = max_indices[n, c, i, j, 1]\n",
    "                    \n",
    "                    # 梯度只流向最大值位置\n",
    "                    dX[n, c, h_idx, w_idx] += dY[n, c, i, j]\n",
    "    \n",
    "    return dX\n",
    "\n",
    "# 測試\n",
    "dY = np.ones((1, 1, 2, 2))\n",
    "dX = maxpool2d_backward_naive(dY, cache)\n",
    "\n",
    "print(\"dY (全 1):\")\n",
    "print(dY[0, 0])\n",
    "print(\"\\ndX (梯度只流向最大值位置):\")\n",
    "print(dX[0, 0])\n",
    "print(\"\\n注意：最大值位置 (6, 8, 14, 16) 在原矩陣中的位置接收到梯度\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 Max Pooling 的梯度流\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# 輸入\n",
    "ax = axes[0]\n",
    "im = ax.imshow(X[0, 0], cmap='Blues', vmin=0, vmax=16)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax.text(j, i, f'{int(X[0,0,i,j])}', ha='center', va='center')\n",
    "ax.set_title('Input X')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Max Pooling 輸出\n",
    "ax = axes[1]\n",
    "im = ax.imshow(Y[0, 0], cmap='Blues', vmin=0, vmax=16)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, f'{int(Y[0,0,i,j])}', ha='center', va='center')\n",
    "ax.set_title('MaxPool Output Y')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# dY\n",
    "ax = axes[2]\n",
    "dY_test = np.array([[[[1, 2], [3, 4]]]], dtype=float)\n",
    "im = ax.imshow(dY_test[0, 0], cmap='Reds', vmin=0, vmax=4)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, f'{int(dY_test[0,0,i,j])}', ha='center', va='center')\n",
    "ax.set_title('Gradient dY')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# dX\n",
    "dX_test = maxpool2d_backward_naive(dY_test, cache)\n",
    "ax = axes[3]\n",
    "im = ax.imshow(dX_test[0, 0], cmap='Reds', vmin=0, vmax=4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        val = dX_test[0, 0, i, j]\n",
    "        if val > 0:\n",
    "            ax.text(j, i, f'{int(val)}', ha='center', va='center', fontweight='bold')\n",
    "ax.set_title('Gradient dX (routed to max positions)')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三部分：Average Pooling\n",
    "\n",
    "Average Pooling 在每個窗口內取平均值。\n",
    "\n",
    "### 前向傳播\n",
    "$$Y[n, c, i, j] = \\frac{1}{k_H \\cdot k_W} \\sum_{p, q} X[n, c, i \\cdot S + p, j \\cdot S + q]$$\n",
    "\n",
    "### 反向傳播\n",
    "梯度**平均分配**給窗口內的所有位置：\n",
    "$$\\frac{\\partial L}{\\partial X[n, c, h, w]} = \\frac{1}{k_H \\cdot k_W} \\cdot dY[n, c, i, j]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgpool2d_forward(X, pool_size, stride=None):\n",
    "    \"\"\"\n",
    "    Average Pooling 前向傳播\n",
    "    \"\"\"\n",
    "    N, C, H, W = X.shape\n",
    "    \n",
    "    if isinstance(pool_size, int):\n",
    "        kH, kW = pool_size, pool_size\n",
    "    else:\n",
    "        kH, kW = pool_size\n",
    "    \n",
    "    if stride is None:\n",
    "        stride = kH\n",
    "    \n",
    "    H_out = (H - kH) // stride + 1\n",
    "    W_out = (W - kW) // stride + 1\n",
    "    \n",
    "    Y = np.zeros((N, C, H_out, W_out))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    window = X[n, c, h_start:h_start+kH, w_start:w_start+kW]\n",
    "                    Y[n, c, i, j] = np.mean(window)\n",
    "    \n",
    "    cache = {'X_shape': X.shape, 'pool_size': (kH, kW), 'stride': stride}\n",
    "    return Y, cache\n",
    "\n",
    "def avgpool2d_backward(dY, cache):\n",
    "    \"\"\"\n",
    "    Average Pooling 反向傳播\n",
    "    \"\"\"\n",
    "    X_shape = cache['X_shape']\n",
    "    kH, kW = cache['pool_size']\n",
    "    stride = cache['stride']\n",
    "    \n",
    "    N, C, H, W = X_shape\n",
    "    _, _, H_out, W_out = dY.shape\n",
    "    \n",
    "    dX = np.zeros(X_shape)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    \n",
    "                    # 梯度平均分配\n",
    "                    dX[n, c, h_start:h_start+kH, w_start:w_start+kW] += dY[n, c, i, j] / (kH * kW)\n",
    "    \n",
    "    return dX\n",
    "\n",
    "# 測試\n",
    "Y_avg, cache_avg = avgpool2d_forward(X, pool_size=2, stride=2)\n",
    "dX_avg = avgpool2d_backward(dY_test, cache_avg)\n",
    "\n",
    "print(\"輸入:\")\n",
    "print(X[0, 0])\n",
    "print(\"\\nAverage Pooling 輸出:\")\n",
    "print(Y_avg[0, 0])\n",
    "print(\"\\ndY:\")\n",
    "print(dY_test[0, 0])\n",
    "print(\"\\ndX (Average Pooling):\")\n",
    "print(dX_avg[0, 0])\n",
    "print(\"\\n注意：梯度被平均分配到每個窗口的 4 個位置\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四部分：完整的 Pooling 類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    \"\"\"\n",
    "    Max Pooling 層\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pool_size, stride=None):\n",
    "        if isinstance(pool_size, int):\n",
    "            self.pool_size = (pool_size, pool_size)\n",
    "        else:\n",
    "            self.pool_size = pool_size\n",
    "        \n",
    "        self.stride = stride if stride is not None else self.pool_size[0]\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        N, C, H, W = X.shape\n",
    "        kH, kW = self.pool_size\n",
    "        S = self.stride\n",
    "        \n",
    "        H_out = (H - kH) // S + 1\n",
    "        W_out = (W - kW) // S + 1\n",
    "        \n",
    "        Y = np.zeros((N, C, H_out, W_out))\n",
    "        max_indices = np.zeros((N, C, H_out, W_out, 2), dtype=int)\n",
    "        \n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(H_out):\n",
    "                    for j in range(W_out):\n",
    "                        h_start = i * S\n",
    "                        w_start = j * S\n",
    "                        window = X[n, c, h_start:h_start+kH, w_start:w_start+kW]\n",
    "                        Y[n, c, i, j] = np.max(window)\n",
    "                        max_pos = np.unravel_index(np.argmax(window), window.shape)\n",
    "                        max_indices[n, c, i, j, 0] = h_start + max_pos[0]\n",
    "                        max_indices[n, c, i, j, 1] = w_start + max_pos[1]\n",
    "        \n",
    "        self.cache = (X.shape, max_indices)\n",
    "        return Y\n",
    "    \n",
    "    def backward(self, dY):\n",
    "        X_shape, max_indices = self.cache\n",
    "        N, C, H, W = X_shape\n",
    "        _, _, H_out, W_out = dY.shape\n",
    "        \n",
    "        dX = np.zeros(X_shape)\n",
    "        \n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(H_out):\n",
    "                    for j in range(W_out):\n",
    "                        h_idx = max_indices[n, c, i, j, 0]\n",
    "                        w_idx = max_indices[n, c, i, j, 1]\n",
    "                        dX[n, c, h_idx, w_idx] += dY[n, c, i, j]\n",
    "        \n",
    "        return dX\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MaxPool2D(pool_size={self.pool_size}, stride={self.stride})\"\n",
    "\n",
    "\n",
    "class AvgPool2D:\n",
    "    \"\"\"\n",
    "    Average Pooling 層\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pool_size, stride=None):\n",
    "        if isinstance(pool_size, int):\n",
    "            self.pool_size = (pool_size, pool_size)\n",
    "        else:\n",
    "            self.pool_size = pool_size\n",
    "        \n",
    "        self.stride = stride if stride is not None else self.pool_size[0]\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        N, C, H, W = X.shape\n",
    "        kH, kW = self.pool_size\n",
    "        S = self.stride\n",
    "        \n",
    "        H_out = (H - kH) // S + 1\n",
    "        W_out = (W - kW) // S + 1\n",
    "        \n",
    "        Y = np.zeros((N, C, H_out, W_out))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(H_out):\n",
    "                    for j in range(W_out):\n",
    "                        h_start = i * S\n",
    "                        w_start = j * S\n",
    "                        Y[n, c, i, j] = np.mean(X[n, c, h_start:h_start+kH, w_start:w_start+kW])\n",
    "        \n",
    "        self.cache = (X.shape, )\n",
    "        return Y\n",
    "    \n",
    "    def backward(self, dY):\n",
    "        X_shape, = self.cache\n",
    "        N, C, H, W = X_shape\n",
    "        kH, kW = self.pool_size\n",
    "        S = self.stride\n",
    "        _, _, H_out, W_out = dY.shape\n",
    "        \n",
    "        dX = np.zeros(X_shape)\n",
    "        \n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(H_out):\n",
    "                    for j in range(W_out):\n",
    "                        h_start = i * S\n",
    "                        w_start = j * S\n",
    "                        dX[n, c, h_start:h_start+kH, w_start:w_start+kW] += dY[n, c, i, j] / (kH * kW)\n",
    "        \n",
    "        return dX\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"AvgPool2D(pool_size={self.pool_size}, stride={self.stride})\"\n",
    "\n",
    "# 測試\n",
    "maxpool = MaxPool2D(2, stride=2)\n",
    "avgpool = AvgPool2D(2, stride=2)\n",
    "\n",
    "print(maxpool)\n",
    "print(avgpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五部分：梯度檢驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check_maxpool(X, pool_size, stride, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Max Pooling 梯度檢驗\n",
    "    \"\"\"\n",
    "    pool = MaxPool2D(pool_size, stride)\n",
    "    \n",
    "    # 前向傳播\n",
    "    Y = pool.forward(X)\n",
    "    \n",
    "    # 假設 loss = sum(Y^2)\n",
    "    dY = 2 * Y\n",
    "    \n",
    "    # 反向傳播\n",
    "    dX = pool.backward(dY)\n",
    "    \n",
    "    # 數值梯度\n",
    "    dX_numerical = np.zeros_like(X)\n",
    "    X_test = X.copy()\n",
    "    \n",
    "    for idx in range(X.size):\n",
    "        multi_idx = np.unravel_index(idx, X.shape)\n",
    "        old_val = X_test[multi_idx]\n",
    "        \n",
    "        X_test[multi_idx] = old_val + eps\n",
    "        pool_new = MaxPool2D(pool_size, stride)\n",
    "        Y_plus = pool_new.forward(X_test)\n",
    "        loss_plus = np.sum(Y_plus ** 2)\n",
    "        \n",
    "        X_test[multi_idx] = old_val - eps\n",
    "        pool_new = MaxPool2D(pool_size, stride)\n",
    "        Y_minus = pool_new.forward(X_test)\n",
    "        loss_minus = np.sum(Y_minus ** 2)\n",
    "        \n",
    "        X_test[multi_idx] = old_val\n",
    "        \n",
    "        dX_numerical[multi_idx] = (loss_plus - loss_minus) / (2 * eps)\n",
    "    \n",
    "    diff = np.abs(dX - dX_numerical)\n",
    "    rel_error = np.max(diff / (np.abs(dX) + np.abs(dX_numerical) + 1e-8))\n",
    "    \n",
    "    print(\"=== Max Pooling 梯度檢驗 ===\")\n",
    "    print(f\"最大絕對誤差: {np.max(diff):.2e}\")\n",
    "    print(f\"最大相對誤差: {rel_error:.2e}\")\n",
    "    print(f\"通過: {rel_error < 1e-5}\")\n",
    "    \n",
    "    return rel_error < 1e-5\n",
    "\n",
    "# 測試\n",
    "X_test = np.random.randn(2, 2, 4, 4)\n",
    "gradient_check_maxpool(X_test, pool_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習題\n",
    "\n",
    "### 練習 1：實作 Global Average Pooling\n",
    "\n",
    "Global Average Pooling 對每個通道計算整個空間的平均值，常用於 CNN 的最後一層替代 FC。\n",
    "\n",
    "輸入：$(N, C, H, W)$ → 輸出：$(N, C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool2D:\n",
    "    \"\"\"\n",
    "    Global Average Pooling\n",
    "    \n",
    "    對每個通道計算空間平均值\n",
    "    輸入: (N, C, H, W)\n",
    "    輸出: (N, C)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        前向傳播\n",
    "        \"\"\"\n",
    "        N, C, H, W = X.shape\n",
    "        \n",
    "        # 解答：對 H 和 W 維度取平均\n",
    "        Y = np.mean(X, axis=(2, 3))  # (N, C)\n",
    "        \n",
    "        self.cache = X.shape\n",
    "        return Y\n",
    "    \n",
    "    def backward(self, dY):\n",
    "        \"\"\"\n",
    "        反向傳播\n",
    "        \n",
    "        dY: (N, C)\n",
    "        dX: (N, C, H, W)\n",
    "        \"\"\"\n",
    "        N, C, H, W = self.cache\n",
    "        \n",
    "        # 解答：梯度平均分配到所有空間位置\n",
    "        dX = dY[:, :, np.newaxis, np.newaxis] / (H * W)\n",
    "        dX = np.broadcast_to(dX, (N, C, H, W)).copy()\n",
    "        \n",
    "        return dX\n",
    "\n",
    "# 測試\n",
    "gap = GlobalAvgPool2D()\n",
    "X_test = np.random.randn(2, 3, 4, 4)\n",
    "Y = gap.forward(X_test)\n",
    "\n",
    "print(f\"輸入形狀: {X_test.shape}\")\n",
    "print(f\"輸出形狀: {Y.shape}\")\n",
    "\n",
    "# 驗證\n",
    "print(f\"\\n驗證：第一個通道的平均值\")\n",
    "print(f\"手動計算: {np.mean(X_test[0, 0]):.6f}\")\n",
    "print(f\"GAP 輸出: {Y[0, 0]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Average Pooling 梯度檢驗\n",
    "def gradient_check_gap(X, eps=1e-5):\n",
    "    gap = GlobalAvgPool2D()\n",
    "    \n",
    "    Y = gap.forward(X)\n",
    "    dY = 2 * Y  # loss = sum(Y^2)\n",
    "    dX = gap.backward(dY)\n",
    "    \n",
    "    dX_numerical = np.zeros_like(X)\n",
    "    X_test = X.copy()\n",
    "    \n",
    "    num_checks = min(20, X.size)\n",
    "    indices = np.random.choice(X.size, num_checks, replace=False)\n",
    "    \n",
    "    for idx in indices:\n",
    "        multi_idx = np.unravel_index(idx, X.shape)\n",
    "        old_val = X_test[multi_idx]\n",
    "        \n",
    "        X_test[multi_idx] = old_val + eps\n",
    "        gap_new = GlobalAvgPool2D()\n",
    "        Y_plus = gap_new.forward(X_test)\n",
    "        loss_plus = np.sum(Y_plus ** 2)\n",
    "        \n",
    "        X_test[multi_idx] = old_val - eps\n",
    "        gap_new = GlobalAvgPool2D()\n",
    "        Y_minus = gap_new.forward(X_test)\n",
    "        loss_minus = np.sum(Y_minus ** 2)\n",
    "        \n",
    "        X_test[multi_idx] = old_val\n",
    "        \n",
    "        dX_numerical[multi_idx] = (loss_plus - loss_minus) / (2 * eps)\n",
    "    \n",
    "    max_error = 0\n",
    "    for idx in indices:\n",
    "        multi_idx = np.unravel_index(idx, X.shape)\n",
    "        error = abs(dX[multi_idx] - dX_numerical[multi_idx]) / (abs(dX[multi_idx]) + abs(dX_numerical[multi_idx]) + 1e-8)\n",
    "        max_error = max(max_error, error)\n",
    "    \n",
    "    print(f\"Global Average Pooling 梯度檢驗 - 最大相對誤差: {max_error:.2e}\")\n",
    "    print(f\"通過: {max_error < 1e-5}\")\n",
    "\n",
    "gradient_check_gap(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2：比較 Max Pooling 和 Average Pooling 的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生有結構的測試圖像\n",
    "def create_test_image():\n",
    "    \"\"\"產生有邊緣和紋理的測試圖像\"\"\"\n",
    "    img = np.zeros((16, 16))\n",
    "    \n",
    "    # 加入一些特徵\n",
    "    img[2:6, 2:6] = 1       # 左上角方塊\n",
    "    img[10:14, 10:14] = 1   # 右下角方塊\n",
    "    img[6:10, :] = 0.5      # 水平條紋\n",
    "    \n",
    "    # 加入一些雜訊\n",
    "    img += np.random.randn(16, 16) * 0.1\n",
    "    \n",
    "    return img[np.newaxis, np.newaxis, :, :]  # (1, 1, 16, 16)\n",
    "\n",
    "img = create_test_image()\n",
    "\n",
    "# 應用不同的池化\n",
    "maxpool = MaxPool2D(2, stride=2)\n",
    "avgpool = AvgPool2D(2, stride=2)\n",
    "\n",
    "img_maxpool = maxpool.forward(img)\n",
    "img_avgpool = avgpool.forward(img)\n",
    "\n",
    "# 視覺化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "im = ax.imshow(img[0, 0], cmap='gray')\n",
    "ax.set_title(f'Original ({img.shape[2]}x{img.shape[3]})')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "ax = axes[1]\n",
    "im = ax.imshow(img_maxpool[0, 0], cmap='gray')\n",
    "ax.set_title(f'Max Pooling ({img_maxpool.shape[2]}x{img_maxpool.shape[3]})')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "ax = axes[2]\n",
    "im = ax.imshow(img_avgpool[0, 0], cmap='gray')\n",
    "ax.set_title(f'Average Pooling ({img_avgpool.shape[2]}x{img_avgpool.shape[3]})')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"觀察：\")\n",
    "print(\"- Max Pooling 保留了最強的特徵（高值），對邊緣和紋理更敏感\")\n",
    "print(\"- Average Pooling 產生更平滑的結果，但可能丟失細節\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3：Flatten 層\n",
    "\n",
    "Flatten 層將多維特徵圖展平成一維向量，連接卷積層和全連接層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \"\"\"\n",
    "    Flatten 層\n",
    "    \n",
    "    將 (N, C, H, W) 展平成 (N, C*H*W)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        前向傳播\n",
    "        \"\"\"\n",
    "        self.cache = X.shape\n",
    "        N = X.shape[0]\n",
    "        return X.reshape(N, -1)\n",
    "    \n",
    "    def backward(self, dY):\n",
    "        \"\"\"\n",
    "        反向傳播\n",
    "        \"\"\"\n",
    "        return dY.reshape(self.cache)\n",
    "\n",
    "# 測試\n",
    "flatten = Flatten()\n",
    "X_test = np.random.randn(2, 3, 4, 4)\n",
    "Y = flatten.forward(X_test)\n",
    "\n",
    "print(f\"輸入形狀: {X_test.shape}\")\n",
    "print(f\"輸出形狀: {Y.shape}\")\n",
    "print(f\"預期: (2, {3*4*4}) = (2, 48)\")\n",
    "\n",
    "# 反向傳播\n",
    "dY = np.random.randn(*Y.shape)\n",
    "dX = flatten.backward(dY)\n",
    "print(f\"\\ndX 形狀: {dX.shape} (應與輸入相同)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "在這個 notebook 中，我們學習了：\n",
    "\n",
    "### Pooling 層的作用\n",
    "1. 下採樣，減少計算量\n",
    "2. 提供一定的平移不變性\n",
    "3. 增大後續層的感受野\n",
    "\n",
    "### Max Pooling vs Average Pooling\n",
    "\n",
    "| 特性 | Max Pooling | Average Pooling |\n",
    "|------|-------------|----------------|\n",
    "| 前向 | 取最大值 | 取平均值 |\n",
    "| 反向 | 梯度只流向 max 位置 | 梯度平均分配 |\n",
    "| 特點 | 保留最強特徵 | 產生平滑結果 |\n",
    "| 常見用途 | CNN 中間層 | GAP 用於最後層 |\n",
    "\n",
    "### 反向傳播的關鍵\n",
    "\n",
    "- **Max Pooling**：需要記錄最大值位置，梯度「路由」到該位置\n",
    "- **Average Pooling**：梯度除以窗口大小後均勻分配\n",
    "\n",
    "### 下一步\n",
    "\n",
    "我們已經有了所有 CNN 的基本組件！接下來將組裝成一個完整的 **LeNet** 網路。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
