{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 效能基礎 - GIL、多執行緒與 Benchmarking\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "1. 理解 Python GIL（Global Interpreter Lock）\n",
    "2. 了解 numpy 的內建多執行緒（BLAS/OpenMP）\n",
    "3. 學習正確的 benchmarking 方法\n",
    "4. 檢查和設定多執行緒環境\n",
    "\n",
    "## 為什麼這很重要？\n",
    "\n",
    "你有 32 執行緒的 CPU，但如果不理解 Python 的執行模型，\n",
    "可能只用到了 1 個核心的效能！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "print(f\"CPU cores available: {multiprocessing.cpu_count()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第一部分：Python GIL（Global Interpreter Lock）\n",
    "\n",
    "### 1.1 GIL 是什麼？\n",
    "\n",
    "**GIL** 是一個互斥鎖（mutex），它保護 Python 物件的存取，\n",
    "**一次只允許一個執行緒執行 Python bytecode**。\n",
    "\n",
    "```\n",
    "╔═══════════════════════════════════════════════════╗\n",
    "║              Python Interpreter                    ║\n",
    "╠═══════════════════════════════════════════════════╣\n",
    "║                      GIL                          ║\n",
    "║                       │                           ║\n",
    "║         ┌─────────────┼─────────────┐             ║\n",
    "║         ▼             ▼             ▼             ║\n",
    "║    Thread 1      Thread 2      Thread 3          ║\n",
    "║    (running)     (blocked)     (blocked)         ║\n",
    "╚═══════════════════════════════════════════════════╝\n",
    "\n",
    "同一時間只有一個 thread 可以執行 Python 程式碼！\n",
    "```\n",
    "\n",
    "### 1.2 為什麼有 GIL？\n",
    "\n",
    "- Python 使用 reference counting 做記憶體管理\n",
    "- 多執行緒同時修改 reference count 會造成 race condition\n",
    "- GIL 是最簡單的解決方案（雖然犧牲了並行性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實驗：GIL 對純 Python 計算的影響\n",
    "\n",
    "def pure_python_work(n):\n",
    "    \"\"\"CPU-bound 的純 Python 迴圈\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "N = 5_000_000\n",
    "\n",
    "# 單執行緒\n",
    "start = time.time()\n",
    "result1 = pure_python_work(N)\n",
    "result2 = pure_python_work(N)\n",
    "time_sequential = time.time() - start\n",
    "print(f\"Sequential (2 tasks): {time_sequential:.3f}s\")\n",
    "\n",
    "# 多執行緒（使用 threading）\n",
    "def thread_worker(n, results, idx):\n",
    "    results[idx] = pure_python_work(n)\n",
    "\n",
    "results = [None, None]\n",
    "start = time.time()\n",
    "t1 = threading.Thread(target=thread_worker, args=(N, results, 0))\n",
    "t2 = threading.Thread(target=thread_worker, args=(N, results, 1))\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "time_threaded = time.time() - start\n",
    "print(f\"Threaded (2 threads): {time_threaded:.3f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {time_sequential / time_threaded:.2f}x\")\n",
    "print(\"\\n觀察：使用 threading 並沒有加速，甚至可能更慢！\")\n",
    "print(\"這是因為 GIL 不允許真正的並行執行 Python bytecode。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實驗：用 multiprocessing 繞過 GIL\n",
    "\n",
    "def mp_worker(n):\n",
    "    return pure_python_work(n)\n",
    "\n",
    "# multiprocessing 使用獨立的 process，每個有自己的 GIL\n",
    "start = time.time()\n",
    "with multiprocessing.Pool(processes=2) as pool:\n",
    "    results = pool.map(mp_worker, [N, N])\n",
    "time_multiprocess = time.time() - start\n",
    "print(f\"Multiprocessing (2 processes): {time_multiprocess:.3f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup vs sequential: {time_sequential / time_multiprocess:.2f}x\")\n",
    "print(\"\\n觀察：multiprocessing 真的能並行執行！\")\n",
    "print(\"但注意：multiprocessing 有進程間通訊的開銷。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 GIL 的例外情況\n",
    "\n",
    "GIL 在以下情況會被釋放：\n",
    "\n",
    "1. **I/O 操作**：讀寫檔案、網路請求時會釋放 GIL\n",
    "2. **C 擴展**：numpy、scipy 等 C 擴展在計算時可以釋放 GIL\n",
    "3. **長時間的 C 函數呼叫**：如 numpy 的大矩陣運算\n",
    "\n",
    "這就是為什麼 numpy 可以利用多核心！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第二部分：NumPy 的內建多執行緒\n",
    "\n",
    "### 2.1 NumPy 的後端庫\n",
    "\n",
    "NumPy 的矩陣運算使用底層的 BLAS/LAPACK 庫：\n",
    "\n",
    "- **OpenBLAS**: 開源，大多數 Linux 發行版預設\n",
    "- **Intel MKL**: Intel 優化版，在 Intel CPU 上通常更快\n",
    "- **Apple Accelerate**: macOS 預設\n",
    "\n",
    "這些庫已經**內建多執行緒支援**！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 numpy 的配置\n",
    "\n",
    "print(\"NumPy configuration:\")\n",
    "print(\"=\" * 50)\n",
    "np.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查環境變數\n",
    "\n",
    "print(\"Thread-related environment variables:\")\n",
    "print(\"=\" * 50)\n",
    "vars_to_check = [\n",
    "    'OMP_NUM_THREADS',      # OpenMP threads\n",
    "    'OPENBLAS_NUM_THREADS', # OpenBLAS threads\n",
    "    'MKL_NUM_THREADS',      # Intel MKL threads\n",
    "    'NUMEXPR_NUM_THREADS',  # NumExpr threads\n",
    "]\n",
    "\n",
    "for var in vars_to_check:\n",
    "    value = os.environ.get(var, 'not set')\n",
    "    print(f\"{var}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實驗：NumPy 多執行緒的效果\n",
    "\n",
    "def benchmark_matmul(size, n_trials=5):\n",
    "    \"\"\"測量矩陣乘法的時間\"\"\"\n",
    "    A = np.random.randn(size, size).astype(np.float64)\n",
    "    B = np.random.randn(size, size).astype(np.float64)\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(n_trials):\n",
    "        start = time.time()\n",
    "        C = A @ B\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "# 測試不同大小\n",
    "sizes = [500, 1000, 2000, 3000]\n",
    "\n",
    "print(\"Matrix multiplication benchmark:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Size':>10} {'Time (s)':>15} {'GFLOPS':>15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for size in sizes:\n",
    "    mean_time, std_time = benchmark_matmul(size)\n",
    "    # FLOPS for matrix multiply: 2 * N^3\n",
    "    flops = 2 * size**3\n",
    "    gflops = flops / mean_time / 1e9\n",
    "    print(f\"{size:>10} {mean_time:>12.4f} ± {std_time:.4f} {gflops:>12.2f}\")\n",
    "\n",
    "print(\"\\n觀察：NumPy 的矩陣乘法使用 BLAS，會自動利用多核心。\")\n",
    "print(\"如果你打開系統監視器，會看到多個 CPU 核心都在工作。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實驗：設定執行緒數量的影響\n",
    "# 注意：這個設定必須在 import numpy 之前！這裡只是示範。\n",
    "\n",
    "def show_thread_effect():\n",
    "    \"\"\"這個函數展示如何設定執行緒數\n",
    "    \n",
    "    實際使用時，應該在 Python 程式開頭設定：\n",
    "    \n",
    "    import os\n",
    "    os.environ['OMP_NUM_THREADS'] = '4'  # 限制為 4 執行緒\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = '4'\n",
    "    os.environ['MKL_NUM_THREADS'] = '4'\n",
    "    import numpy as np  # 在設定之後 import\n",
    "    \"\"\"\n",
    "    print(\"設定執行緒數的方法：\")\n",
    "    print()\n",
    "    print(\"方法 1: 環境變數（在 Python 啟動前）\")\n",
    "    print(\"  $ export OMP_NUM_THREADS=4\")\n",
    "    print(\"  $ python my_script.py\")\n",
    "    print()\n",
    "    print(\"方法 2: 在程式開頭（import numpy 之前）\")\n",
    "    print(\"  import os\")\n",
    "    print(\"  os.environ['OMP_NUM_THREADS'] = '4'\")\n",
    "    print(\"  import numpy as np\")\n",
    "    print()\n",
    "    print(\"方法 3: 使用 threadpoolctl（可以動態調整）\")\n",
    "    print(\"  from threadpoolctl import threadpool_limits\")\n",
    "    print(\"  with threadpool_limits(limits=4):\")\n",
    "    print(\"      # 這裡的計算只用 4 個執行緒\")\n",
    "\n",
    "show_thread_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 什麼操作會用到多執行緒？\n",
    "\n",
    "**會用多執行緒的操作**（呼叫 BLAS/LAPACK）：\n",
    "- 矩陣乘法：`A @ B`, `np.dot`, `np.matmul`\n",
    "- 線性代數：`np.linalg.inv`, `np.linalg.svd`, `np.linalg.eig`\n",
    "- 大的向量內積\n",
    "\n",
    "**不會用多執行緒的操作**（純 NumPy）：\n",
    "- Element-wise 運算：`A + B`, `A * B`, `np.sin(A)`\n",
    "- Reduction：`np.sum`, `np.mean`, `np.max`\n",
    "- 索引、reshape、transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較：BLAS 操作 vs 純 NumPy 操作\n",
    "\n",
    "size = 2000\n",
    "A = np.random.randn(size, size)\n",
    "B = np.random.randn(size, size)\n",
    "\n",
    "# 矩陣乘法（用 BLAS，多執行緒）\n",
    "start = time.time()\n",
    "for _ in range(5):\n",
    "    C = A @ B\n",
    "time_matmul = (time.time() - start) / 5\n",
    "\n",
    "# Element-wise 乘法（純 NumPy，單執行緒）\n",
    "start = time.time()\n",
    "for _ in range(5):\n",
    "    D = A * B\n",
    "time_elementwise = (time.time() - start) / 5\n",
    "\n",
    "# Sum（純 NumPy，單執行緒）\n",
    "start = time.time()\n",
    "for _ in range(5):\n",
    "    s = np.sum(A)\n",
    "time_sum = (time.time() - start) / 5\n",
    "\n",
    "print(f\"Matrix multiplication (BLAS): {time_matmul:.4f}s\")\n",
    "print(f\"Element-wise multiplication:  {time_elementwise:.4f}s\")\n",
    "print(f\"Sum reduction:                {time_sum:.4f}s\")\n",
    "print(\"\\n觀察：矩陣乘法雖然計算量最大，但因為用了 BLAS 多執行緒，\")\n",
    "print(\"相對而言並沒有慢很多。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第三部分：Benchmarking 方法\n",
    "\n",
    "### 3.1 正確的 Benchmarking 原則\n",
    "\n",
    "1. **Warmup**：第一次執行可能較慢（JIT、cache）\n",
    "2. **多次執行**：取平均值和標準差\n",
    "3. **控制變因**：固定隨機種子、輸入大小\n",
    "4. **使用正確的計時器**：`time.perf_counter()` 比 `time.time()` 精確\n",
    "5. **避免干擾**：關閉其他程式、使用專用環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"簡單的計時器 context manager\"\"\"\n",
    "    \n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "        self.elapsed = 0\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self.elapsed = time.perf_counter() - self.start\n",
    "        if self.name:\n",
    "            print(f\"{self.name}: {self.elapsed:.4f}s\")\n",
    "\n",
    "\n",
    "def benchmark(func, *args, n_warmup=2, n_trials=10, **kwargs):\n",
    "    \"\"\"\n",
    "    標準化的 benchmark 函數\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        要測試的函數\n",
    "    n_warmup : int\n",
    "        預熱次數\n",
    "    n_trials : int\n",
    "        正式測試次數\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean : float\n",
    "        平均時間\n",
    "    std : float\n",
    "        標準差\n",
    "    \"\"\"\n",
    "    # Warmup\n",
    "    for _ in range(n_warmup):\n",
    "        func(*args, **kwargs)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(n_trials):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        times.append(time.perf_counter() - start)\n",
    "    \n",
    "    return np.mean(times), np.std(times), result\n",
    "\n",
    "\n",
    "# 示範使用\n",
    "def example_func(size):\n",
    "    A = np.random.randn(size, size)\n",
    "    return np.linalg.svd(A, compute_uv=False)\n",
    "\n",
    "mean, std, _ = benchmark(example_func, 500)\n",
    "print(f\"SVD of 500x500 matrix: {mean:.4f} ± {std:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 %timeit 魔術命令（Jupyter 專用）\n",
    "\n",
    "A = np.random.randn(500, 500)\n",
    "B = np.random.randn(500, 500)\n",
    "\n",
    "print(\"使用 %%timeit 魔術命令：\")\n",
    "%timeit A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Profiling：找出瓶頸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "def profile_code(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Profile 一段程式碼並印出結果\n",
    "    \"\"\"\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    \n",
    "    result = func(*args, **kwargs)\n",
    "    \n",
    "    pr.disable()\n",
    "    \n",
    "    # 格式化輸出\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "    ps.print_stats(15)  # 只印前 15 個\n",
    "    print(s.getvalue())\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def example_workflow():\n",
    "    \"\"\"一個包含多種操作的範例工作流程\"\"\"\n",
    "    # 生成數據\n",
    "    X = np.random.randn(1000, 100)\n",
    "    \n",
    "    # 正規化\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    \n",
    "    # 計算 covariance\n",
    "    cov = X.T @ X / len(X)\n",
    "    \n",
    "    # SVD\n",
    "    U, S, Vt = np.linalg.svd(cov)\n",
    "    \n",
    "    # PCA projection\n",
    "    X_proj = X @ Vt[:10].T\n",
    "    \n",
    "    return X_proj\n",
    "\n",
    "\n",
    "print(\"Profiling example workflow:\")\n",
    "print(\"=\" * 70)\n",
    "result = profile_code(example_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 記憶體 Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_memory(arr):\n",
    "    \"\"\"估計 numpy array 的記憶體使用\"\"\"\n",
    "    bytes_per_element = arr.itemsize\n",
    "    total_bytes = arr.nbytes\n",
    "    \n",
    "    # 轉換為人類可讀格式\n",
    "    if total_bytes < 1024:\n",
    "        return f\"{total_bytes} B\"\n",
    "    elif total_bytes < 1024**2:\n",
    "        return f\"{total_bytes/1024:.2f} KB\"\n",
    "    elif total_bytes < 1024**3:\n",
    "        return f\"{total_bytes/1024**2:.2f} MB\"\n",
    "    else:\n",
    "        return f\"{total_bytes/1024**3:.2f} GB\"\n",
    "\n",
    "\n",
    "# 不同資料類型的記憶體使用\n",
    "print(\"Memory usage by data type (1000x1000 matrix):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dtypes = [np.float16, np.float32, np.float64, np.int32, np.int64]\n",
    "for dtype in dtypes:\n",
    "    arr = np.zeros((1000, 1000), dtype=dtype)\n",
    "    print(f\"{str(dtype):20s}: {estimate_memory(arr):>10s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算你的 CNN 所需記憶體\n",
    "\n",
    "def estimate_cnn_memory(batch_size, in_channels, height, width, \n",
    "                        layer_configs, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    估計 CNN forward pass 的記憶體需求\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    layer_configs : list of dict\n",
    "        每一層的配置，例如：\n",
    "        {'type': 'conv', 'out_channels': 32, 'kernel_size': 3}\n",
    "        {'type': 'pool', 'kernel_size': 2}\n",
    "    \"\"\"\n",
    "    bytes_per_element = np.dtype(dtype).itemsize\n",
    "    total_bytes = 0\n",
    "    \n",
    "    H, W = height, width\n",
    "    C = in_channels\n",
    "    \n",
    "    print(f\"{'Layer':20s} {'Output Shape':25s} {'Memory':>15s}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Input\n",
    "    input_bytes = batch_size * C * H * W * bytes_per_element\n",
    "    total_bytes += input_bytes\n",
    "    print(f\"{'Input':20s} {str((batch_size, C, H, W)):25s} {estimate_memory(np.zeros(1, dtype=dtype)):>15s}\")\n",
    "    \n",
    "    for i, config in enumerate(layer_configs):\n",
    "        if config['type'] == 'conv':\n",
    "            out_C = config['out_channels']\n",
    "            k = config.get('kernel_size', 3)\n",
    "            p = config.get('padding', 0)\n",
    "            s = config.get('stride', 1)\n",
    "            \n",
    "            H = (H + 2*p - k) // s + 1\n",
    "            W = (W + 2*p - k) // s + 1\n",
    "            \n",
    "            # 參數記憶體\n",
    "            param_bytes = (out_C * C * k * k + out_C) * bytes_per_element\n",
    "            # 輸出記憶體\n",
    "            output_bytes = batch_size * out_C * H * W * bytes_per_element\n",
    "            # im2col 的記憶體（如果使用）\n",
    "            im2col_bytes = batch_size * H * W * C * k * k * bytes_per_element\n",
    "            \n",
    "            layer_bytes = param_bytes + output_bytes + im2col_bytes\n",
    "            total_bytes += layer_bytes\n",
    "            C = out_C\n",
    "            \n",
    "            name = f\"Conv{i+1}({out_C}ch, {k}x{k})\"\n",
    "            shape = (batch_size, out_C, H, W)\n",
    "            \n",
    "        elif config['type'] == 'pool':\n",
    "            k = config.get('kernel_size', 2)\n",
    "            H = H // k\n",
    "            W = W // k\n",
    "            \n",
    "            output_bytes = batch_size * C * H * W * bytes_per_element\n",
    "            layer_bytes = output_bytes\n",
    "            total_bytes += layer_bytes\n",
    "            \n",
    "            name = f\"Pool{i+1}({k}x{k})\"\n",
    "            shape = (batch_size, C, H, W)\n",
    "        \n",
    "        arr = np.zeros(shape, dtype=dtype)\n",
    "        print(f\"{name:20s} {str(shape):25s} {estimate_memory(arr):>15s}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    total_arr = np.zeros(int(total_bytes / bytes_per_element), dtype=dtype)\n",
    "    print(f\"{'Total (estimated)':20s} {'-':25s} {estimate_memory(total_arr):>15s}\")\n",
    "\n",
    "\n",
    "# 範例：LeNet-style 網路\n",
    "layers = [\n",
    "    {'type': 'conv', 'out_channels': 32, 'kernel_size': 3, 'padding': 1},\n",
    "    {'type': 'pool', 'kernel_size': 2},\n",
    "    {'type': 'conv', 'out_channels': 64, 'kernel_size': 3, 'padding': 1},\n",
    "    {'type': 'pool', 'kernel_size': 2},\n",
    "    {'type': 'conv', 'out_channels': 128, 'kernel_size': 3, 'padding': 1},\n",
    "]\n",
    "\n",
    "print(\"\\nMemory estimation for a small CNN:\")\n",
    "print(\"=\" * 60)\n",
    "estimate_cnn_memory(batch_size=32, in_channels=3, height=64, width=64,\n",
    "                    layer_configs=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第四部分：Threading vs Multiprocessing 總結\n",
    "\n",
    "### 選擇指南\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                     Python 並行策略選擇                          │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  ┌──────────────────┐     ┌──────────────────┐                 │\n",
    "│  │   CPU-bound ?    │ Yes │ 用 numpy/scipy   │                 │\n",
    "│  │  (計算密集型)     ├────►│ (自動多執行緒)    │                 │\n",
    "│  └────────┬─────────┘     └──────────────────┘                 │\n",
    "│           │ No                                                  │\n",
    "│           ▼                                                     │\n",
    "│  ┌──────────────────┐     ┌──────────────────┐                 │\n",
    "│  │    I/O-bound ?   │ Yes │   threading      │                 │\n",
    "│  │   (I/O 密集型)    ├────►│  (網路/檔案)      │                 │\n",
    "│  └────────┬─────────┘     └──────────────────┘                 │\n",
    "│           │ No                                                  │\n",
    "│           ▼                                                     │\n",
    "│  ┌──────────────────┐     ┌──────────────────┐                 │\n",
    "│  │  純 Python 迴圈  │ Yes │  multiprocessing │                 │\n",
    "│  │  無法向量化？    ├────►│   (用多進程)      │                 │\n",
    "│  └────────┬─────────┘     └──────────────────┘                 │\n",
    "│           │ No                                                  │\n",
    "│           ▼                                                     │\n",
    "│  ┌──────────────────┐                                          │\n",
    "│  │   考慮向量化      │                                          │\n",
    "│  │  或 numba/cython │                                          │\n",
    "│  └──────────────────┘                                          │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 總結實驗：不同策略的效能\n",
    "\n",
    "def task_cpu_bound_python(n):\n",
    "    \"\"\"純 Python CPU 密集任務\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i % 1000\n",
    "    return total\n",
    "\n",
    "def task_cpu_bound_numpy(size):\n",
    "    \"\"\"NumPy CPU 密集任務\"\"\"\n",
    "    A = np.random.randn(size, size)\n",
    "    B = np.random.randn(size, size)\n",
    "    return A @ B\n",
    "\n",
    "def task_io_bound():\n",
    "    \"\"\"I/O 密集任務（模擬）\"\"\"\n",
    "    time.sleep(0.1)  # 模擬 I/O 等待\n",
    "    return True\n",
    "\n",
    "print(\"Performance Summary:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. 純 Python CPU-bound\n",
    "print(\"\\n1. Pure Python CPU-bound (n=1,000,000):\")\n",
    "with Timer(\"   Sequential (2 tasks)\"):\n",
    "    task_cpu_bound_python(1_000_000)\n",
    "    task_cpu_bound_python(1_000_000)\n",
    "\n",
    "# 2. NumPy CPU-bound\n",
    "print(\"\\n2. NumPy CPU-bound (500x500 matmul, 10 times):\")\n",
    "with Timer(\"   Sequential\"):\n",
    "    for _ in range(10):\n",
    "        task_cpu_bound_numpy(500)\n",
    "\n",
    "# 3. I/O bound with threading\n",
    "print(\"\\n3. I/O bound (10 x 0.1s sleep):\")\n",
    "with Timer(\"   Sequential\"):\n",
    "    for _ in range(10):\n",
    "        task_io_bound()\n",
    "\n",
    "def threaded_io():\n",
    "    threads = [threading.Thread(target=task_io_bound) for _ in range(10)]\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "with Timer(\"   Threaded (10 threads)\"):\n",
    "    threaded_io()\n",
    "\n",
    "print(\"\\n結論：\")\n",
    "print(\"- 純 Python 迴圈：用 multiprocessing 或改用 numpy\")\n",
    "print(\"- NumPy 矩陣運算：自動多執行緒，不需要額外處理\")\n",
    "print(\"- I/O 操作：threading 可以有效並行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 總結\n",
    "\n",
    "### Python 效能要點\n",
    "\n",
    "1. **GIL** 限制了純 Python 多執行緒的效能\n",
    "   - 用 `multiprocessing` 繞過 GIL\n",
    "   - 用 numpy/scipy 的 C 擴展自動釋放 GIL\n",
    "\n",
    "2. **NumPy 多執行緒**\n",
    "   - BLAS 操作（矩陣乘法、SVD 等）自動多執行緒\n",
    "   - 可用環境變數控制執行緒數\n",
    "   - Element-wise 操作不會多執行緒\n",
    "\n",
    "3. **Benchmarking**\n",
    "   - 使用 `time.perf_counter()` 而非 `time.time()`\n",
    "   - 包含 warmup 階段\n",
    "   - 多次測量取平均\n",
    "   - 用 profiling 找出真正的瓶頸\n",
    "\n",
    "### 下一步\n",
    "\n",
    "- 學習向量化技巧（減少 Python 迴圈）\n",
    "- 學習 im2col 把卷積轉成矩陣乘法（利用 BLAS 多執行緒）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
