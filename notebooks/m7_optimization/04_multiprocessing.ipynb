{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing - 平行處理\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "1. 理解什麼時候適合用 multiprocessing\n",
    "2. 學習 Pool.map / Pool.starmap 的使用\n",
    "3. 在訓練和推論中應用平行化\n",
    "4. 了解共享記憶體和資料傳遞的開銷\n",
    "\n",
    "## 核心原則\n",
    "\n",
    "> **Multiprocessing 適合「完全獨立」的任務**。\n",
    "> 如果任務之間有依賴或需要頻繁通訊，開銷可能超過收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, shared_memory\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Available CPU cores: {mp.cpu_count()}\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第一部分：Multiprocessing 基礎\n",
    "\n",
    "### 1.1 Process vs Thread\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                      Threading                                  │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│  ┌─────────┐   ┌─────────┐   ┌─────────┐                       │\n",
    "│  │ Thread 1│   │ Thread 2│   │ Thread 3│    共享記憶體空間     │\n",
    "│  └────┬────┘   └────┬────┘   └────┬────┘                       │\n",
    "│       │             │             │                            │\n",
    "│       └─────────────┼─────────────┘                            │\n",
    "│                     ▼                                          │\n",
    "│            ┌───────────────┐                                   │\n",
    "│            │     GIL      │  <-- 同一時間只有一個執行          │\n",
    "│            └───────────────┘                                   │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    Multiprocessing                              │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐             │\n",
    "│  │  Process 1  │  │  Process 2  │  │  Process 3  │             │\n",
    "│  │  (自己的GIL) │  │  (自己的GIL) │  │  (自己的GIL) │             │\n",
    "│  │  獨立記憶體  │  │  獨立記憶體  │  │  獨立記憶體  │             │\n",
    "│  └─────────────┘  └─────────────┘  └─────────────┘             │\n",
    "│         │               │               │                      │\n",
    "│         └───────────────┼───────────────┘                      │\n",
    "│                         ▼                                      │\n",
    "│                真正的並行執行（多核心）                         │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本使用：Pool.map\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"簡單的任務：計算平方\"\"\"\n",
    "    return x * x\n",
    "\n",
    "def heavy_computation(x):\n",
    "    \"\"\"稍微重一點的任務\"\"\"\n",
    "    # 模擬一些計算\n",
    "    result = 0\n",
    "    for i in range(100000):\n",
    "        result += i * x\n",
    "    return result\n",
    "\n",
    "# 測試資料\n",
    "data = list(range(100))\n",
    "\n",
    "# Sequential\n",
    "start = time.perf_counter()\n",
    "results_seq = [heavy_computation(x) for x in data]\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential: {time_seq:.3f}s\")\n",
    "\n",
    "# Parallel (4 processes)\n",
    "start = time.perf_counter()\n",
    "with Pool(processes=4) as pool:\n",
    "    results_par = pool.map(heavy_computation, data)\n",
    "time_par = time.perf_counter() - start\n",
    "print(f\"Parallel (4 processes): {time_par:.3f}s\")\n",
    "print(f\"Speedup: {time_seq / time_par:.2f}x\")\n",
    "\n",
    "# 驗證結果相同\n",
    "print(f\"Results match: {results_seq == results_par}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試不同進程數的效果\n",
    "\n",
    "def benchmark_pool_size(func, data, max_processes=None):\n",
    "    \"\"\"測試不同進程數的效能\"\"\"\n",
    "    if max_processes is None:\n",
    "        max_processes = mp.cpu_count()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Sequential\n",
    "    start = time.perf_counter()\n",
    "    _ = [func(x) for x in data]\n",
    "    time_seq = time.perf_counter() - start\n",
    "    results.append((1, time_seq))\n",
    "    print(f\"  1 process (seq): {time_seq:.3f}s\")\n",
    "    \n",
    "    # Parallel with different numbers of processes\n",
    "    for n_proc in [2, 4, 8, min(16, max_processes)]:\n",
    "        if n_proc > max_processes:\n",
    "            continue\n",
    "        start = time.perf_counter()\n",
    "        with Pool(processes=n_proc) as pool:\n",
    "            _ = pool.map(func, data)\n",
    "        time_par = time.perf_counter() - start\n",
    "        results.append((n_proc, time_par))\n",
    "        print(f\"  {n_proc} processes: {time_par:.3f}s (speedup: {time_seq/time_par:.2f}x)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Benchmark with different pool sizes:\")\n",
    "print(\"=\" * 50)\n",
    "results = benchmark_pool_size(heavy_computation, list(range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pool.starmap（多參數）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_params(x, multiplier, offset):\n",
    "    \"\"\"帶多個參數的函數\"\"\"\n",
    "    result = 0\n",
    "    for i in range(50000):\n",
    "        result += i * x * multiplier + offset\n",
    "    return result\n",
    "\n",
    "# 準備參數\n",
    "args_list = [(i, 2, 100) for i in range(50)]  # (x, multiplier, offset)\n",
    "\n",
    "# Sequential\n",
    "start = time.perf_counter()\n",
    "results_seq = [process_with_params(*args) for args in args_list]\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential: {time_seq:.3f}s\")\n",
    "\n",
    "# Parallel with starmap\n",
    "start = time.perf_counter()\n",
    "with Pool(processes=4) as pool:\n",
    "    results_par = pool.starmap(process_with_params, args_list)\n",
    "time_par = time.perf_counter() - start\n",
    "print(f\"Parallel (starmap): {time_par:.3f}s\")\n",
    "print(f\"Speedup: {time_seq / time_par:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第二部分：資料傳遞的開銷\n",
    "\n",
    "**關鍵問題**：Multiprocessing 需要把資料**序列化（pickle）**後傳給子進程，\n",
    "這有額外的開銷！\n",
    "\n",
    "如果任務本身很輕量，開銷可能超過收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實驗：任務太輕時 multiprocessing 反而慢\n",
    "\n",
    "def very_light_task(x):\n",
    "    \"\"\"非常輕量的任務\"\"\"\n",
    "    return x + 1\n",
    "\n",
    "def light_task(x):\n",
    "    \"\"\"輕量任務\"\"\"\n",
    "    return np.sum(x)\n",
    "\n",
    "def heavy_task(x):\n",
    "    \"\"\"重量任務：矩陣運算\"\"\"\n",
    "    return np.sum(np.dot(x, x.T))\n",
    "\n",
    "# 測試不同權重的任務\n",
    "print(\"Task complexity vs Multiprocessing benefit:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Very light task\n",
    "data_light = list(range(10000))\n",
    "\n",
    "start = time.perf_counter()\n",
    "_ = [very_light_task(x) for x in data_light]\n",
    "time_seq = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "with Pool(4) as pool:\n",
    "    _ = pool.map(very_light_task, data_light)\n",
    "time_par = time.perf_counter() - start\n",
    "\n",
    "print(f\"Very light task (x+1):\")\n",
    "print(f\"  Sequential: {time_seq:.4f}s\")\n",
    "print(f\"  Parallel:   {time_par:.4f}s\")\n",
    "print(f\"  Speedup:    {time_seq/time_par:.2f}x {'(slower!)' if time_par > time_seq else ''}\")\n",
    "\n",
    "# Heavy task with numpy arrays\n",
    "data_heavy = [np.random.randn(200, 200).astype(np.float32) for _ in range(100)]\n",
    "\n",
    "start = time.perf_counter()\n",
    "_ = [heavy_task(x) for x in data_heavy]\n",
    "time_seq = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "with Pool(4) as pool:\n",
    "    _ = pool.map(heavy_task, data_heavy)\n",
    "time_par = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nHeavy task (200x200 matrix multiply):\")\n",
    "print(f\"  Sequential: {time_seq:.4f}s\")\n",
    "print(f\"  Parallel:   {time_par:.4f}s\")\n",
    "print(f\"  Speedup:    {time_seq/time_par:.2f}x\")\n",
    "\n",
    "print(\"\\n結論：\")\n",
    "print(\"- 任務太輕時，pickle/unpickle 的開銷超過收益\")\n",
    "print(\"- 任務夠重時，multiprocessing 才有優勢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第三部分：圖片處理的平行化\n",
    "\n",
    "這是 multiprocessing 最典型的應用場景：\n",
    "- 每張圖片的處理完全獨立\n",
    "- 處理時間夠長（值得平行化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模擬圖片預處理 pipeline\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    模擬圖片預處理流程\n",
    "    \n",
    "    包含：\n",
    "    - 正規化\n",
    "    - 高斯模糊\n",
    "    - 邊緣檢測\n",
    "    \"\"\"\n",
    "    # 正規化\n",
    "    image = (image - image.mean()) / (image.std() + 1e-8)\n",
    "    \n",
    "    # 高斯模糊（簡化版）\n",
    "    kernel = np.array([[1, 2, 1],\n",
    "                       [2, 4, 2],\n",
    "                       [1, 2, 1]]) / 16.0\n",
    "    \n",
    "    # 卷積\n",
    "    H, W = image.shape\n",
    "    blurred = np.zeros((H-2, W-2))\n",
    "    for i in range(H-2):\n",
    "        for j in range(W-2):\n",
    "            blurred[i, j] = np.sum(image[i:i+3, j:j+3] * kernel)\n",
    "    \n",
    "    # Sobel 邊緣檢測\n",
    "    sobel_x = np.array([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]])\n",
    "    sobel_y = np.array([[-1, -2, -1],\n",
    "                        [0, 0, 0],\n",
    "                        [1, 2, 1]])\n",
    "    \n",
    "    H2, W2 = blurred.shape\n",
    "    grad_x = np.zeros((H2-2, W2-2))\n",
    "    grad_y = np.zeros((H2-2, W2-2))\n",
    "    \n",
    "    for i in range(H2-2):\n",
    "        for j in range(W2-2):\n",
    "            patch = blurred[i:i+3, j:j+3]\n",
    "            grad_x[i, j] = np.sum(patch * sobel_x)\n",
    "            grad_y[i, j] = np.sum(patch * sobel_y)\n",
    "    \n",
    "    edges = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n",
    "# 生成測試圖片\n",
    "n_images = 50\n",
    "images = [np.random.randn(128, 128).astype(np.float32) for _ in range(n_images)]\n",
    "\n",
    "print(f\"Processing {n_images} images of size 128x128:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sequential\n",
    "start = time.perf_counter()\n",
    "results_seq = [preprocess_image(img) for img in images]\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential:             {time_seq:.3f}s\")\n",
    "\n",
    "# Parallel with different pool sizes\n",
    "for n_proc in [2, 4, 8]:\n",
    "    start = time.perf_counter()\n",
    "    with Pool(processes=n_proc) as pool:\n",
    "        results_par = pool.map(preprocess_image, images)\n",
    "    time_par = time.perf_counter() - start\n",
    "    print(f\"Parallel ({n_proc} processes): {time_par:.3f}s (speedup: {time_seq/time_par:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第四部分：訓練中的平行化\n",
    "\n",
    "### 4.1 資料載入平行化\n",
    "\n",
    "這是最常見的訓練優化：在 GPU 計算時，CPU 並行載入下一批資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelDataLoader:\n",
    "    \"\"\"\n",
    "    簡易的平行資料載入器\n",
    "    \n",
    "    使用 multiprocessing 預載入數據\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, preprocess_fn, batch_size=32, n_workers=4):\n",
    "        self.data_list = data_list\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.n_workers = n_workers\n",
    "        \n",
    "        self.n_samples = len(data_list)\n",
    "        self.n_batches = (self.n_samples + batch_size - 1) // batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"生成 batches（平行預處理）\"\"\"\n",
    "        indices = np.random.permutation(self.n_samples)\n",
    "        \n",
    "        with Pool(processes=self.n_workers) as pool:\n",
    "            for i in range(0, self.n_samples, self.batch_size):\n",
    "                batch_indices = indices[i:i + self.batch_size]\n",
    "                batch_data = [self.data_list[idx] for idx in batch_indices]\n",
    "                \n",
    "                # 平行預處理\n",
    "                processed = pool.map(self.preprocess_fn, batch_data)\n",
    "                \n",
    "                yield np.array(processed)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "\n",
    "class SequentialDataLoader:\n",
    "    \"\"\"對照組：順序載入\"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, preprocess_fn, batch_size=32):\n",
    "        self.data_list = data_list\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_samples = len(data_list)\n",
    "        self.n_batches = (self.n_samples + batch_size - 1) // batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.n_samples)\n",
    "        \n",
    "        for i in range(0, self.n_samples, self.batch_size):\n",
    "            batch_indices = indices[i:i + self.batch_size]\n",
    "            batch_data = [self.data_list[idx] for idx in batch_indices]\n",
    "            \n",
    "            # 順序預處理\n",
    "            processed = [self.preprocess_fn(d) for d in batch_data]\n",
    "            \n",
    "            yield np.array(processed)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡化的預處理函數\n",
    "\n",
    "def simple_preprocess(image):\n",
    "    \"\"\"簡單的預處理\"\"\"\n",
    "    # 正規化\n",
    "    image = (image - image.mean()) / (image.std() + 1e-8)\n",
    "    \n",
    "    # 調整大小（模擬）\n",
    "    # 在實際應用中會用 PIL 或其他庫\n",
    "    \n",
    "    # 增加一些計算讓預處理有意義\n",
    "    for _ in range(5):\n",
    "        image = np.clip(image, -3, 3)\n",
    "        image = (image - image.mean()) / (image.std() + 1e-8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "# 生成數據\n",
    "n_samples = 500\n",
    "raw_data = [np.random.randn(64, 64).astype(np.float32) for _ in range(n_samples)]\n",
    "\n",
    "print(f\"Data loading benchmark ({n_samples} samples, batch_size=32):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sequential\n",
    "seq_loader = SequentialDataLoader(raw_data, simple_preprocess, batch_size=32)\n",
    "start = time.perf_counter()\n",
    "for batch in seq_loader:\n",
    "    pass  # 模擬「使用」數據\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential loading:       {time_seq:.3f}s\")\n",
    "\n",
    "# Parallel with different worker counts\n",
    "for n_workers in [2, 4, 8]:\n",
    "    par_loader = ParallelDataLoader(raw_data, simple_preprocess, batch_size=32, n_workers=n_workers)\n",
    "    start = time.perf_counter()\n",
    "    for batch in par_loader:\n",
    "        pass\n",
    "    time_par = time.perf_counter() - start\n",
    "    print(f\"Parallel ({n_workers} workers): {time_par:.3f}s (speedup: {time_seq/time_par:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 推論平行化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模擬一個簡單的 CNN forward pass\n",
    "\n",
    "class SimpleCNN:\n",
    "    \"\"\"簡單的 CNN（用於測試）\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, n_classes=10):\n",
    "        # 簡化的權重\n",
    "        self.conv1_w = np.random.randn(16, in_channels, 3, 3).astype(np.float32) * 0.1\n",
    "        self.conv2_w = np.random.randn(32, 16, 3, 3).astype(np.float32) * 0.1\n",
    "        self.fc_w = np.random.randn(32 * 6 * 6, n_classes).astype(np.float32) * 0.1\n",
    "    \n",
    "    def conv2d(self, x, w):\n",
    "        \"\"\"簡單的卷積（使用 einsum）\"\"\"\n",
    "        N, C, H, W = x.shape\n",
    "        C_out, _, kH, kW = w.shape\n",
    "        out_H = H - kH + 1\n",
    "        out_W = W - kW + 1\n",
    "        \n",
    "        # 使用 stride_tricks\n",
    "        shape = (N, C, kH, kW, out_H, out_W)\n",
    "        strides = x.strides[:2] + x.strides[2:4] + x.strides[2:4]\n",
    "        patches = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n",
    "        \n",
    "        # einsum for convolution\n",
    "        out = np.einsum('nchwij,ocij->nohw', patches, w)\n",
    "        return out\n",
    "    \n",
    "    def maxpool2d(self, x):\n",
    "        \"\"\"2x2 max pooling\"\"\"\n",
    "        N, C, H, W = x.shape\n",
    "        return x.reshape(N, C, H//2, 2, W//2, 2).max(axis=(3, 5))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # Conv1 + ReLU + Pool\n",
    "        x = self.conv2d(x, self.conv1_w)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        \n",
    "        # Conv2 + ReLU + Pool\n",
    "        x = self.conv2d(x, self.conv2_w)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        \n",
    "        # Flatten + FC\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = x @ self.fc_w\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 創建模型\n",
    "model = SimpleCNN(in_channels=1, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為 model 包含 numpy arrays，不能直接 pickle\n",
    "# 需要把模型權重作為參數傳遞\n",
    "\n",
    "def inference_single(args):\n",
    "    \"\"\"單張圖片推論\"\"\"\n",
    "    image, conv1_w, conv2_w, fc_w = args\n",
    "    \n",
    "    # 重建 forward pass\n",
    "    x = image[np.newaxis]  # (1, C, H, W)\n",
    "    \n",
    "    # Conv1\n",
    "    N, C, H, W = x.shape\n",
    "    C_out, _, kH, kW = conv1_w.shape\n",
    "    shape = (N, C, kH, kW, H-kH+1, W-kW+1)\n",
    "    strides = x.strides[:2] + x.strides[2:4] + x.strides[2:4]\n",
    "    patches = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n",
    "    x = np.einsum('nchwij,ocij->nohw', patches, conv1_w)\n",
    "    x = np.maximum(0, x)\n",
    "    x = x.reshape(N, x.shape[1], x.shape[2]//2, 2, x.shape[3]//2, 2).max(axis=(3, 5))\n",
    "    \n",
    "    # Conv2\n",
    "    N, C, H, W = x.shape\n",
    "    C_out, _, kH, kW = conv2_w.shape\n",
    "    shape = (N, C, kH, kW, H-kH+1, W-kW+1)\n",
    "    strides = x.strides[:2] + x.strides[2:4] + x.strides[2:4]\n",
    "    patches = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n",
    "    x = np.einsum('nchwij,ocij->nohw', patches, conv2_w)\n",
    "    x = np.maximum(0, x)\n",
    "    x = x.reshape(N, x.shape[1], x.shape[2]//2, 2, x.shape[3]//2, 2).max(axis=(3, 5))\n",
    "    \n",
    "    # FC\n",
    "    x = x.reshape(N, -1)\n",
    "    x = x @ fc_w\n",
    "    \n",
    "    return x[0]  # 返回單張圖片的結果\n",
    "\n",
    "\n",
    "# 測試推論平行化\n",
    "n_images = 100\n",
    "test_images = [np.random.randn(1, 28, 28).astype(np.float32) for _ in range(n_images)]\n",
    "\n",
    "print(f\"Inference benchmark ({n_images} images):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sequential\n",
    "start = time.perf_counter()\n",
    "results_seq = []\n",
    "for img in test_images:\n",
    "    result = model.forward(img[np.newaxis])\n",
    "    results_seq.append(result[0])\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential: {time_seq:.3f}s\")\n",
    "\n",
    "# Parallel\n",
    "# 準備參數（包含模型權重）\n",
    "args_list = [(img, model.conv1_w, model.conv2_w, model.fc_w) for img in test_images]\n",
    "\n",
    "start = time.perf_counter()\n",
    "with Pool(4) as pool:\n",
    "    results_par = pool.map(inference_single, args_list)\n",
    "time_par = time.perf_counter() - start\n",
    "print(f\"Parallel (4 processes): {time_par:.3f}s\")\n",
    "print(f\"Speedup: {time_seq / time_par:.2f}x\")\n",
    "\n",
    "# Batched inference (通常更快)\n",
    "start = time.perf_counter()\n",
    "batch = np.array(test_images)  # (N, 1, 28, 28)\n",
    "results_batch = model.forward(batch)\n",
    "time_batch = time.perf_counter() - start\n",
    "print(f\"Batched (single process): {time_batch:.3f}s\")\n",
    "print(f\"\\n注意：對於 numpy 運算，batched 通常比 multiprocessing 更快！\")\n",
    "print(\"因為 numpy 本身就用了 BLAS 多執行緒。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第五部分：共享記憶體\n",
    "\n",
    "為了減少資料傳遞的開銷，可以使用共享記憶體。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 shared_memory 避免資料複製\n",
    "\n",
    "def create_shared_array(shape, dtype=np.float32):\n",
    "    \"\"\"創建共享記憶體的 numpy array\"\"\"\n",
    "    size = int(np.prod(shape)) * np.dtype(dtype).itemsize\n",
    "    shm = shared_memory.SharedMemory(create=True, size=size)\n",
    "    arr = np.ndarray(shape, dtype=dtype, buffer=shm.buf)\n",
    "    return arr, shm\n",
    "\n",
    "def worker_with_shared_mem(args):\n",
    "    \"\"\"使用共享記憶體的 worker\"\"\"\n",
    "    shm_name, shape, dtype, start_idx, end_idx = args\n",
    "    \n",
    "    # 連接到共享記憶體\n",
    "    existing_shm = shared_memory.SharedMemory(name=shm_name)\n",
    "    arr = np.ndarray(shape, dtype=dtype, buffer=existing_shm.buf)\n",
    "    \n",
    "    # 處理自己負責的部分\n",
    "    result = 0\n",
    "    for i in range(start_idx, end_idx):\n",
    "        result += np.sum(arr[i] ** 2)\n",
    "    \n",
    "    existing_shm.close()\n",
    "    return result\n",
    "\n",
    "def demonstrate_shared_memory():\n",
    "    \"\"\"展示共享記憶體的使用\"\"\"\n",
    "    # 創建大型數據\n",
    "    data_shape = (1000, 100, 100)\n",
    "    \n",
    "    print(f\"Shared memory demonstration:\")\n",
    "    print(f\"Data shape: {data_shape}\")\n",
    "    print(f\"Data size: {np.prod(data_shape) * 4 / 1024**2:.1f} MB\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 創建共享記憶體 array\n",
    "    shared_arr, shm = create_shared_array(data_shape)\n",
    "    shared_arr[:] = np.random.randn(*data_shape).astype(np.float32)\n",
    "    \n",
    "    try:\n",
    "        n_processes = 4\n",
    "        chunk_size = data_shape[0] // n_processes\n",
    "        \n",
    "        # 準備參數\n",
    "        args_list = [\n",
    "            (shm.name, data_shape, np.float32, i * chunk_size, (i + 1) * chunk_size)\n",
    "            for i in range(n_processes)\n",
    "        ]\n",
    "        \n",
    "        # 使用共享記憶體\n",
    "        start = time.perf_counter()\n",
    "        with Pool(n_processes) as pool:\n",
    "            results = pool.map(worker_with_shared_mem, args_list)\n",
    "        time_shared = time.perf_counter() - start\n",
    "        print(f\"With shared memory: {time_shared:.3f}s\")\n",
    "        \n",
    "        # 對比：不用共享記憶體（每次複製整個 array）\n",
    "        def worker_copy(args):\n",
    "            arr, start_idx, end_idx = args\n",
    "            result = 0\n",
    "            for i in range(start_idx, end_idx):\n",
    "                result += np.sum(arr[i] ** 2)\n",
    "            return result\n",
    "        \n",
    "        # 複製整個 array\n",
    "        regular_arr = np.array(shared_arr)\n",
    "        args_copy = [\n",
    "            (regular_arr, i * chunk_size, (i + 1) * chunk_size)\n",
    "            for i in range(n_processes)\n",
    "        ]\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        with Pool(n_processes) as pool:\n",
    "            results_copy = pool.starmap(worker_copy, args_copy)\n",
    "        time_copy = time.perf_counter() - start\n",
    "        print(f\"Without shared memory: {time_copy:.3f}s\")\n",
    "        \n",
    "        print(f\"Speedup: {time_copy / time_shared:.2f}x\")\n",
    "        \n",
    "    finally:\n",
    "        # 清理共享記憶體\n",
    "        shm.close()\n",
    "        shm.unlink()\n",
    "\n",
    "demonstrate_shared_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第六部分：最佳實踐總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決策流程\n",
    "\n",
    "decision_tree = \"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│               何時使用 Multiprocessing？                         │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  Q1: 任務是否「完全獨立」？                                      │\n",
    "│      │                                                          │\n",
    "│      ├── No → 考慮其他方案（threading for I/O, GPU, etc.）      │\n",
    "│      │                                                          │\n",
    "│      └── Yes → Q2: 單個任務是否「夠重」？                        │\n",
    "│                  │                                              │\n",
    "│                  ├── No → 可能不值得（開銷超過收益）             │\n",
    "│                  │         試試 batch 處理或向量化               │\n",
    "│                  │                                              │\n",
    "│                  └── Yes → Q3: 資料量大嗎？                      │\n",
    "│                              │                                  │\n",
    "│                              ├── Yes → 考慮共享記憶體            │\n",
    "│                              │                                  │\n",
    "│                              └── No → 直接用 Pool.map           │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "適合 Multiprocessing 的場景：\n",
    "✓ 圖片預處理（每張獨立，計算量適中）\n",
    "✓ 資料增強（隨機變換是獨立的）\n",
    "✓ 批量檔案處理\n",
    "✓ 超參數搜索（每組參數獨立訓練）\n",
    "\n",
    "不太適合的場景：\n",
    "✗ numpy 矩陣運算（已經用 BLAS 多執行緒了）\n",
    "✗ 很輕量的任務（開銷超過收益）\n",
    "✗ 需要頻繁通訊的任務\n",
    "✗ 訓練中的梯度計算（有依賴關係）\n",
    "\"\"\"\n",
    "\n",
    "print(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終效能比較\n",
    "\n",
    "def final_benchmark():\n",
    "    \"\"\"綜合效能比較\"\"\"\n",
    "    \n",
    "    print(\"Final Performance Comparison\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 場景 1：圖片預處理\n",
    "    print(\"\\n1. Image Preprocessing (50 images, 128x128):\")\n",
    "    images = [np.random.randn(128, 128).astype(np.float32) for _ in range(50)]\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    _ = [preprocess_image(img) for img in images]\n",
    "    t_seq = time.perf_counter() - start\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    with Pool(4) as pool:\n",
    "        _ = pool.map(preprocess_image, images)\n",
    "    t_par = time.perf_counter() - start\n",
    "    \n",
    "    print(f\"   Sequential: {t_seq:.3f}s\")\n",
    "    print(f\"   Parallel:   {t_par:.3f}s (speedup: {t_seq/t_par:.2f}x)\")\n",
    "    \n",
    "    # 場景 2：矩陣運算\n",
    "    print(\"\\n2. Matrix Operations (already multi-threaded in BLAS):\")\n",
    "    A = np.random.randn(2000, 2000).astype(np.float64)\n",
    "    B = np.random.randn(2000, 2000).astype(np.float64)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    C = A @ B\n",
    "    t_blas = time.perf_counter() - start\n",
    "    \n",
    "    print(f\"   BLAS matmul (2000x2000): {t_blas:.3f}s\")\n",
    "    print(f\"   (Already using multiple threads internally)\")\n",
    "    \n",
    "    # 場景 3：CNN 推論\n",
    "    print(\"\\n3. CNN Inference (100 images):\")\n",
    "    model = SimpleCNN()\n",
    "    test_imgs = np.random.randn(100, 1, 28, 28).astype(np.float32)\n",
    "    \n",
    "    # Batched\n",
    "    start = time.perf_counter()\n",
    "    _ = model.forward(test_imgs)\n",
    "    t_batch = time.perf_counter() - start\n",
    "    \n",
    "    print(f\"   Batched inference: {t_batch:.4f}s\")\n",
    "    print(f\"   (Batching is usually better than multiprocessing for NumPy)\")\n",
    "\n",
    "final_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 總結\n",
    "\n",
    "### Multiprocessing 要點\n",
    "\n",
    "1. **適用場景**\n",
    "   - 完全獨立的任務\n",
    "   - 任務夠重（預處理時間 > 通訊開銷）\n",
    "   - 不是 numpy 密集運算（BLAS 已經多執行緒）\n",
    "\n",
    "2. **常用 API**\n",
    "   - `Pool.map(func, iterable)`: 單參數函數\n",
    "   - `Pool.starmap(func, iterable)`: 多參數函數\n",
    "   - `Pool.apply_async`: 非同步執行\n",
    "\n",
    "3. **效能考量**\n",
    "   - Pickle/Unpickle 有開銷\n",
    "   - 進程間通訊有開銷\n",
    "   - 共享記憶體可減少大資料的傳遞成本\n",
    "\n",
    "4. **典型應用**\n",
    "   - 資料載入和預處理\n",
    "   - 批量檔案處理\n",
    "   - 超參數搜索\n",
    "\n",
    "### 優化優先順序（再次強調）\n",
    "\n",
    "1. 演算法改進 >> 底層優化\n",
    "2. 向量化 >> Multiprocessing（對於 numpy）\n",
    "3. Batching >> 單張處理\n",
    "4. Multiprocessing 用於「真正獨立且夠重」的任務"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
