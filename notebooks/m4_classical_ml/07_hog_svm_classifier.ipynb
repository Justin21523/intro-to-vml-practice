{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4.7: HOG + SVM 影像分類器（專案整合）\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "這是 Module 4 的整合專案。完成後你將能夠：\n",
    "\n",
    "1. 結合 HOG 特徵擷取與 SVM 分類器\n",
    "2. 建立完整的影像分類 pipeline\n",
    "3. 評估分類器效能（準確率、混淆矩陣）\n",
    "4. 理解傳統機器學習在電腦視覺中的應用\n",
    "\n",
    "## 背景知識\n",
    "\n",
    "HOG + SVM 是經典的物件偵測方法，Dalal & Triggs (2005) 最初用於行人偵測。\n",
    "\n",
    "**Pipeline**：\n",
    "1. 影像預處理（調整大小、灰階化）\n",
    "2. HOG 特徵擷取\n",
    "3. SVM 分類\n",
    "\n",
    "---\n",
    "\n",
    "## 參考論文\n",
    "\n",
    "- Dalal & Triggs, *\"Histograms of Oriented Gradients for Human Detection\"*, CVPR 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"環境設定完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: HOG 特徵擷取器（從 Module 3 複製）\n",
    "\n",
    "我們需要使用之前實作的 HOG 特徵擷取器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOG 實作（從 Module 3 移植）\n",
    "\n",
    "def compute_gradients(image):\n",
    "    \"\"\"\n",
    "    計算圖像的梯度大小和方向\n",
    "    \"\"\"\n",
    "    H, W = image.shape\n",
    "    img = image.astype(np.float64)\n",
    "    \n",
    "    # Gx\n",
    "    gx = np.zeros((H, W), dtype=np.float64)\n",
    "    gx[:, 1:-1] = img[:, 2:] - img[:, :-2]\n",
    "    gx[:, 0] = img[:, 1] - img[:, 0]\n",
    "    gx[:, -1] = img[:, -1] - img[:, -2]\n",
    "    \n",
    "    # Gy\n",
    "    gy = np.zeros((H, W), dtype=np.float64)\n",
    "    gy[1:-1, :] = img[2:, :] - img[:-2, :]\n",
    "    gy[0, :] = img[1, :] - img[0, :]\n",
    "    gy[-1, :] = img[-1, :] - img[-2, :]\n",
    "    \n",
    "    magnitude = np.sqrt(gx**2 + gy**2)\n",
    "    direction = np.degrees(np.arctan2(gy, gx)) % 180\n",
    "    \n",
    "    return magnitude, direction\n",
    "\n",
    "\n",
    "class HOGDescriptor:\n",
    "    \"\"\"\n",
    "    HOG 特徵描述子\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cell_size=8, block_size=2, num_bins=9):\n",
    "        self.cell_size = cell_size\n",
    "        self.block_size = block_size\n",
    "        self.num_bins = num_bins\n",
    "        self.block_dim = block_size * block_size * num_bins\n",
    "    \n",
    "    def _compute_cell_histogram(self, magnitude, direction):\n",
    "        \"\"\"計算 cell 直方圖（soft binning）\"\"\"\n",
    "        bin_width = 180.0 / self.num_bins\n",
    "        bin_pos = direction / bin_width\n",
    "        \n",
    "        bin_left = np.floor(bin_pos).astype(int) % self.num_bins\n",
    "        bin_right = (bin_left + 1) % self.num_bins\n",
    "        weight_right = bin_pos - np.floor(bin_pos)\n",
    "        weight_left = 1 - weight_right\n",
    "        \n",
    "        hist = np.zeros(self.num_bins)\n",
    "        np.add.at(hist, bin_left.flatten(), (magnitude * weight_left).flatten())\n",
    "        np.add.at(hist, bin_right.flatten(), (magnitude * weight_right).flatten())\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def _normalize_block(self, block, eps=1e-5):\n",
    "        \"\"\"L2-Hys 正規化\"\"\"\n",
    "        norm = np.sqrt(np.sum(block**2) + eps)\n",
    "        normalized = block / norm\n",
    "        normalized = np.minimum(normalized, 0.2)\n",
    "        norm2 = np.sqrt(np.sum(normalized**2) + eps)\n",
    "        return normalized / norm2\n",
    "    \n",
    "    def compute(self, image):\n",
    "        \"\"\"\n",
    "        計算 HOG 特徵\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.ndarray\n",
    "            灰階圖像，shape (H, W)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        features : np.ndarray\n",
    "            HOG 特徵向量\n",
    "        \"\"\"\n",
    "        H, W = image.shape\n",
    "        num_cells_y = H // self.cell_size\n",
    "        num_cells_x = W // self.cell_size\n",
    "        \n",
    "        # 計算梯度\n",
    "        magnitude, direction = compute_gradients(image)\n",
    "        \n",
    "        # 計算 cell 直方圖\n",
    "        cell_hists = np.zeros((num_cells_y, num_cells_x, self.num_bins))\n",
    "        \n",
    "        for cy in range(num_cells_y):\n",
    "            for cx in range(num_cells_x):\n",
    "                y_start = cy * self.cell_size\n",
    "                x_start = cx * self.cell_size\n",
    "                \n",
    "                cell_mag = magnitude[y_start:y_start+self.cell_size,\n",
    "                                    x_start:x_start+self.cell_size]\n",
    "                cell_dir = direction[y_start:y_start+self.cell_size,\n",
    "                                    x_start:x_start+self.cell_size]\n",
    "                \n",
    "                cell_hists[cy, cx] = self._compute_cell_histogram(cell_mag, cell_dir)\n",
    "        \n",
    "        # Block normalization\n",
    "        num_blocks_y = num_cells_y - self.block_size + 1\n",
    "        num_blocks_x = num_cells_x - self.block_size + 1\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for by in range(num_blocks_y):\n",
    "            for bx in range(num_blocks_x):\n",
    "                block = cell_hists[by:by+self.block_size,\n",
    "                                  bx:bx+self.block_size].flatten()\n",
    "                features.append(self._normalize_block(block))\n",
    "        \n",
    "        return np.concatenate(features)\n",
    "    \n",
    "    def get_feature_dim(self, height, width):\n",
    "        \"\"\"計算特徵維度\"\"\"\n",
    "        num_cells_y = height // self.cell_size\n",
    "        num_cells_x = width // self.cell_size\n",
    "        num_blocks_y = num_cells_y - self.block_size + 1\n",
    "        num_blocks_x = num_cells_x - self.block_size + 1\n",
    "        return num_blocks_y * num_blocks_x * self.block_dim\n",
    "\n",
    "\n",
    "# 測試 HOG\n",
    "print(\"=== 測試 HOG ===\")\n",
    "\n",
    "hog = HOGDescriptor(cell_size=8, block_size=2, num_bins=9)\n",
    "\n",
    "# 測試圖像\n",
    "test_img = np.random.rand(64, 64) * 255\n",
    "features = hog.compute(test_img)\n",
    "\n",
    "print(f\"圖像大小: 64x64\")\n",
    "print(f\"HOG 特徵維度: {len(features)}\")\n",
    "print(f\"預期維度: {hog.get_feature_dim(64, 64)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Linear SVM（從 Module 4.4 複製）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM 實作\n",
    "\n",
    "class LinearSVM:\n",
    "    \"\"\"\n",
    "    Linear SVM with Hinge Loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C=1.0):\n",
    "        self.C = C\n",
    "        self.reg = 1.0 / C\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "    \n",
    "    def fit(self, X, y, lr=0.001, n_iter=1000, verbose=False):\n",
    "        \"\"\"\n",
    "        訓練 SVM\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray, shape (N, D)\n",
    "        y : np.ndarray, shape (N,)\n",
    "            標籤為 -1 或 +1\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        y = np.where(y == 0, -1, y)\n",
    "        \n",
    "        self.w = np.zeros(D)\n",
    "        self.b = 0.0\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            scores = X @ self.w + self.b\n",
    "            margins = y * scores\n",
    "            violating = (margins < 1).astype(float)\n",
    "            \n",
    "            dw = -(1/N) * (X.T @ (violating * y)) + self.reg * self.w\n",
    "            db = -(1/N) * np.sum(violating * y)\n",
    "            \n",
    "            self.w = self.w - lr * dw\n",
    "            self.b = self.b - lr * db\n",
    "            \n",
    "            if verbose and (i + 1) % (n_iter // 10) == 0:\n",
    "                hinge = np.mean(np.maximum(0, 1 - margins))\n",
    "                print(f\"Iter {i+1}: Hinge Loss = {hinge:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"預測標籤（-1 或 +1）\"\"\"\n",
    "        scores = X @ self.w + self.b\n",
    "        return np.sign(scores)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"返回決策分數\"\"\"\n",
    "        return X @ self.w + self.b\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"計算準確率\"\"\"\n",
    "        y = np.where(y == 0, -1, y)\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "\n",
    "# Multi-class SVM (One-vs-All)\n",
    "class MultiClassSVM:\n",
    "    \"\"\"\n",
    "    使用 One-vs-All 的多分類 SVM\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes, C=1.0):\n",
    "        self.n_classes = n_classes\n",
    "        self.C = C\n",
    "        self.classifiers = []\n",
    "    \n",
    "    def fit(self, X, y, lr=0.001, n_iter=1000, verbose=False):\n",
    "        self.classifiers = []\n",
    "        \n",
    "        for k in range(self.n_classes):\n",
    "            if verbose:\n",
    "                print(f\"訓練分類器 {k}...\")\n",
    "            \n",
    "            y_binary = np.where(y == k, 1, -1)\n",
    "            \n",
    "            svm = LinearSVM(C=self.C)\n",
    "            svm.fit(X, y_binary, lr=lr, n_iter=n_iter, verbose=False)\n",
    "            \n",
    "            self.classifiers.append(svm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        scores = np.zeros((X.shape[0], self.n_classes))\n",
    "        \n",
    "        for k, svm in enumerate(self.classifiers):\n",
    "            scores[:, k] = svm.decision_function(X)\n",
    "        \n",
    "        return np.argmax(scores, axis=1)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "\n",
    "print(\"SVM 類別載入完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: 建立合成資料集\n",
    "\n",
    "為了測試，我們建立一個簡單的合成資料集：不同形狀的圖像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立合成圖像資料集\n",
    "\n",
    "def create_circle_image(size=64):\n",
    "    \"\"\"建立圓形圖像\"\"\"\n",
    "    img = np.ones((size, size)) * 255\n",
    "    center = size // 2\n",
    "    radius = size // 4\n",
    "    \n",
    "    for y in range(size):\n",
    "        for x in range(size):\n",
    "            if (x - center)**2 + (y - center)**2 < radius**2:\n",
    "                img[y, x] = 50\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def create_square_image(size=64):\n",
    "    \"\"\"建立方形圖像\"\"\"\n",
    "    img = np.ones((size, size)) * 255\n",
    "    margin = size // 4\n",
    "    img[margin:size-margin, margin:size-margin] = 50\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_triangle_image(size=64):\n",
    "    \"\"\"建立三角形圖像\"\"\"\n",
    "    img = np.ones((size, size)) * 255\n",
    "    center_x = size // 2\n",
    "    top_y = size // 4\n",
    "    bottom_y = 3 * size // 4\n",
    "    \n",
    "    for y in range(top_y, bottom_y):\n",
    "        # 三角形寬度隨 y 增加\n",
    "        progress = (y - top_y) / (bottom_y - top_y)\n",
    "        half_width = int(progress * size // 4)\n",
    "        img[y, center_x - half_width:center_x + half_width] = 50\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def create_cross_image(size=64):\n",
    "    \"\"\"建立十字形圖像\"\"\"\n",
    "    img = np.ones((size, size)) * 255\n",
    "    center = size // 2\n",
    "    arm_width = size // 8\n",
    "    arm_length = size // 4\n",
    "    \n",
    "    # 垂直部分\n",
    "    img[center-arm_length:center+arm_length, center-arm_width:center+arm_width] = 50\n",
    "    # 水平部分\n",
    "    img[center-arm_width:center+arm_width, center-arm_length:center+arm_length] = 50\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def add_noise_and_transform(img, noise_std=10, shift_range=5):\n",
    "    \"\"\"\n",
    "    添加噪音和隨機位移\n",
    "    \"\"\"\n",
    "    # 添加高斯噪音\n",
    "    noisy = img + np.random.randn(*img.shape) * noise_std\n",
    "    \n",
    "    # 隨機位移\n",
    "    shift_y = np.random.randint(-shift_range, shift_range + 1)\n",
    "    shift_x = np.random.randint(-shift_range, shift_range + 1)\n",
    "    shifted = np.roll(np.roll(noisy, shift_y, axis=0), shift_x, axis=1)\n",
    "    \n",
    "    return np.clip(shifted, 0, 255)\n",
    "\n",
    "\n",
    "def generate_shape_dataset(n_per_class=100, size=64, noise_std=15):\n",
    "    \"\"\"\n",
    "    生成形狀分類資料集\n",
    "    \n",
    "    類別：\n",
    "    0 - Circle\n",
    "    1 - Square\n",
    "    2 - Triangle\n",
    "    3 - Cross\n",
    "    \"\"\"\n",
    "    creators = [create_circle_image, create_square_image, \n",
    "                create_triangle_image, create_cross_image]\n",
    "    class_names = ['Circle', 'Square', 'Triangle', 'Cross']\n",
    "    n_classes = len(creators)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for class_idx, creator in enumerate(creators):\n",
    "        base_img = creator(size)\n",
    "        \n",
    "        for _ in range(n_per_class):\n",
    "            img = add_noise_and_transform(base_img, noise_std)\n",
    "            X.append(img)\n",
    "            y.append(class_idx)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # 打亂\n",
    "    idx = np.random.permutation(len(y))\n",
    "    \n",
    "    return X[idx], y[idx], class_names\n",
    "\n",
    "\n",
    "# 生成資料集\n",
    "print(\"=== 生成形狀分類資料集 ===\")\n",
    "\n",
    "X_images, y_labels, class_names = generate_shape_dataset(n_per_class=150, size=64, noise_std=15)\n",
    "\n",
    "print(f\"資料集大小: {X_images.shape}\")\n",
    "print(f\"類別: {class_names}\")\n",
    "print(f\"類別分布: {np.bincount(y_labels)}\")\n",
    "\n",
    "# 視覺化樣本\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "\n",
    "for row, class_idx in enumerate(range(4)):\n",
    "    class_samples = X_images[y_labels == class_idx][:5]\n",
    "    for col, img in enumerate(class_samples):\n",
    "        axes[row, col].imshow(img, cmap='gray')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(class_names[class_idx])\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('形狀分類資料集樣本', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: 完整的 HOG + SVM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOGSVMClassifier:\n",
    "    \"\"\"\n",
    "    HOG + SVM 影像分類器\n",
    "    \n",
    "    Pipeline:\n",
    "    1. HOG 特徵擷取\n",
    "    2. SVM 分類\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classes : int\n",
    "        類別數\n",
    "    hog_cell_size : int\n",
    "        HOG cell 大小\n",
    "    svm_C : float\n",
    "        SVM 正則化參數\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes, hog_cell_size=8, svm_C=1.0):\n",
    "        self.n_classes = n_classes\n",
    "        self.hog = HOGDescriptor(cell_size=hog_cell_size, block_size=2, num_bins=9)\n",
    "        self.svm = MultiClassSVM(n_classes=n_classes, C=svm_C)\n",
    "        self.feature_dim = None\n",
    "    \n",
    "    def _extract_features(self, images):\n",
    "        \"\"\"\n",
    "        對一批圖像擷取 HOG 特徵\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        images : np.ndarray, shape (N, H, W)\n",
    "            灰階圖像陣列\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        features : np.ndarray, shape (N, D)\n",
    "            HOG 特徵矩陣\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        for img in images:\n",
    "            feat = self.hog.compute(img)\n",
    "            features_list.append(feat)\n",
    "        \n",
    "        return np.array(features_list)\n",
    "    \n",
    "    def fit(self, X_images, y, lr=0.001, n_iter=1000, verbose=True):\n",
    "        \"\"\"\n",
    "        訓練分類器\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_images : np.ndarray, shape (N, H, W)\n",
    "            訓練圖像\n",
    "        y : np.ndarray, shape (N,)\n",
    "            類別標籤\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Step 1: 擷取 HOG 特徵...\")\n",
    "        \n",
    "        X_features = self._extract_features(X_images)\n",
    "        self.feature_dim = X_features.shape[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  特徵維度: {self.feature_dim}\")\n",
    "            print(f\"  訓練樣本數: {len(X_images)}\")\n",
    "            print(\"\\nStep 2: 訓練 SVM...\")\n",
    "        \n",
    "        self.svm.fit(X_features, y, lr=lr, n_iter=n_iter, verbose=verbose)\n",
    "        \n",
    "        if verbose:\n",
    "            train_acc = self.score(X_images, y)\n",
    "            print(f\"\\n訓練完成！訓練準確率: {train_acc:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_images):\n",
    "        \"\"\"\n",
    "        預測類別\n",
    "        \"\"\"\n",
    "        X_features = self._extract_features(X_images)\n",
    "        return self.svm.predict(X_features)\n",
    "    \n",
    "    def score(self, X_images, y):\n",
    "        \"\"\"\n",
    "        計算準確率\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_images)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "def train_test_split(X, y, test_ratio=0.2, seed=42):\n",
    "    \"\"\"簡單的訓練/測試集分割\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    N = len(y)\n",
    "    n_test = int(N * test_ratio)\n",
    "    \n",
    "    idx = np.random.permutation(N)\n",
    "    test_idx = idx[:n_test]\n",
    "    train_idx = idx[n_test:]\n",
    "    \n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "\n",
    "# 訓練模型\n",
    "print(\"=== 訓練 HOG + SVM 分類器 ===\")\n",
    "\n",
    "# 分割資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels, test_ratio=0.2)\n",
    "\n",
    "print(f\"訓練集: {len(X_train)} 樣本\")\n",
    "print(f\"測試集: {len(X_test)} 樣本\\n\")\n",
    "\n",
    "# 建立和訓練分類器\n",
    "classifier = HOGSVMClassifier(n_classes=4, hog_cell_size=8, svm_C=10.0)\n",
    "classifier.fit(X_train, y_train, lr=0.0001, n_iter=2000, verbose=True)\n",
    "\n",
    "# 評估\n",
    "test_acc = classifier.score(X_test, y_test)\n",
    "print(f\"\\n測試準確率: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: 模型評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩陣\n",
    "\n",
    "def compute_confusion_matrix(y_true, y_pred, n_classes):\n",
    "    \"\"\"計算混淆矩陣\"\"\"\n",
    "    confusion = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    for true, pred in zip(y_true.astype(int), y_pred.astype(int)):\n",
    "        confusion[true, pred] += 1\n",
    "    return confusion\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion, class_names):\n",
    "    \"\"\"視覺化混淆矩陣\"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(confusion, cmap='Blues')\n",
    "    plt.colorbar(im, ax=ax, label='Count')\n",
    "    \n",
    "    ax.set_xticks(range(n_classes))\n",
    "    ax.set_yticks(range(n_classes))\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            color = 'white' if confusion[i, j] > confusion.max() / 2 else 'black'\n",
    "            ax.text(j, i, str(confusion[i, j]), ha='center', va='center', color=color, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compute_metrics(y_true, y_pred, n_classes, class_names):\n",
    "    \"\"\"計算各類別的精確率、召回率、F1\"\"\"\n",
    "    confusion = compute_confusion_matrix(y_true, y_pred, n_classes)\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    for i, name in enumerate(class_names):\n",
    "        tp = confusion[i, i]\n",
    "        fp = np.sum(confusion[:, i]) - tp\n",
    "        fn = np.sum(confusion[i, :]) - tp\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics[name] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# 評估測試集\n",
    "print(\"=== 模型評估 ===\")\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion = compute_confusion_matrix(y_test, y_pred, 4)\n",
    "\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(confusion)\n",
    "\n",
    "# 視覺化\n",
    "plot_confusion_matrix(confusion, class_names)\n",
    "plt.show()\n",
    "\n",
    "# 詳細指標\n",
    "metrics = compute_metrics(y_test, y_pred, 4, class_names)\n",
    "\n",
    "print(\"\\n各類別指標:\")\n",
    "print(f\"{'Class':<12} {'Precision':>10} {'Recall':>10} {'F1':>10}\")\n",
    "print(\"-\" * 44)\n",
    "for name, m in metrics.items():\n",
    "    print(f\"{name:<12} {m['precision']:>10.4f} {m['recall']:>10.4f} {m['f1']:>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化一些預測結果\n",
    "\n",
    "def visualize_predictions(images, y_true, y_pred, class_names, n_show=16):\n",
    "    \"\"\"視覺化預測結果\"\"\"\n",
    "    n_cols = 4\n",
    "    n_rows = (n_show + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(n_show, len(images))):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        \n",
    "        true_label = class_names[y_true[i]]\n",
    "        pred_label = class_names[y_pred[i]]\n",
    "        \n",
    "        color = 'green' if y_true[i] == y_pred[i] else 'red'\n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}', color=color)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # 隱藏多餘的 axes\n",
    "    for i in range(len(images), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('預測結果（綠色=正確，紅色=錯誤）', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# 隨機選擇一些測試樣本\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.choice(len(X_test), 16, replace=False)\n",
    "\n",
    "visualize_predictions(\n",
    "    X_test[sample_idx], \n",
    "    y_test[sample_idx], \n",
    "    y_pred[sample_idx], \n",
    "    class_names\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 顯示一些錯誤樣本\n",
    "print(\"\\n錯誤分類的樣本:\")\n",
    "error_idx = np.where(y_test != y_pred)[0]\n",
    "print(f\"共 {len(error_idx)} 個錯誤（共 {len(y_test)} 個測試樣本）\")\n",
    "\n",
    "if len(error_idx) > 0:\n",
    "    n_show = min(8, len(error_idx))\n",
    "    visualize_predictions(\n",
    "        X_test[error_idx[:n_show]], \n",
    "        y_test[error_idx[:n_show]], \n",
    "        y_pred[error_idx[:n_show]], \n",
    "        class_names,\n",
    "        n_show=n_show\n",
    "    )\n",
    "    plt.suptitle('錯誤分類樣本', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: 參數調整實驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同 SVM C 值的影響\n",
    "print(\"=== SVM C 參數實驗 ===\")\n",
    "\n",
    "C_values = [0.1, 1.0, 10.0, 100.0]\n",
    "results = []\n",
    "\n",
    "for C in C_values:\n",
    "    clf = HOGSVMClassifier(n_classes=4, hog_cell_size=8, svm_C=C)\n",
    "    clf.fit(X_train, y_train, lr=0.0001, n_iter=1500, verbose=False)\n",
    "    \n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    results.append({'C': C, 'train_acc': train_acc, 'test_acc': test_acc})\n",
    "    print(f\"C={C:>6.1f}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "\n",
    "# 視覺化\n",
    "plt.figure(figsize=(10, 5))\n",
    "C_list = [r['C'] for r in results]\n",
    "train_accs = [r['train_acc'] for r in results]\n",
    "test_accs = [r['test_acc'] for r in results]\n",
    "\n",
    "plt.semilogx(C_list, train_accs, 'bo-', linewidth=2, label='Train')\n",
    "plt.semilogx(C_list, test_accs, 'ro-', linewidth=2, label='Test')\n",
    "plt.xlabel('SVM C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('SVM C 參數 vs 準確率')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同 HOG cell size 的影響\n",
    "print(\"=== HOG Cell Size 實驗 ===\")\n",
    "\n",
    "cell_sizes = [4, 8, 16]\n",
    "results_cell = []\n",
    "\n",
    "for cell_size in cell_sizes:\n",
    "    clf = HOGSVMClassifier(n_classes=4, hog_cell_size=cell_size, svm_C=10.0)\n",
    "    clf.fit(X_train, y_train, lr=0.0001, n_iter=1500, verbose=False)\n",
    "    \n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    results_cell.append({\n",
    "        'cell_size': cell_size, \n",
    "        'feature_dim': clf.feature_dim,\n",
    "        'train_acc': train_acc, \n",
    "        'test_acc': test_acc\n",
    "    })\n",
    "    print(f\"Cell size={cell_size}: Feature dim={clf.feature_dim}, Train={train_acc:.4f}, Test={test_acc:.4f}\")\n",
    "\n",
    "# 視覺化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 準確率\n",
    "axes[0].bar(np.arange(len(cell_sizes)) - 0.15, [r['train_acc'] for r in results_cell], 0.3, label='Train')\n",
    "axes[0].bar(np.arange(len(cell_sizes)) + 0.15, [r['test_acc'] for r in results_cell], 0.3, label='Test')\n",
    "axes[0].set_xticks(range(len(cell_sizes)))\n",
    "axes[0].set_xticklabels([f'{c}x{c}' for c in cell_sizes])\n",
    "axes[0].set_xlabel('Cell Size')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Cell Size vs 準確率')\n",
    "axes[0].legend()\n",
    "\n",
    "# 特徵維度\n",
    "axes[1].bar(range(len(cell_sizes)), [r['feature_dim'] for r in results_cell])\n",
    "axes[1].set_xticks(range(len(cell_sizes)))\n",
    "axes[1].set_xticklabels([f'{c}x{c}' for c in cell_sizes])\n",
    "axes[1].set_xlabel('Cell Size')\n",
    "axes[1].set_ylabel('Feature Dimension')\n",
    "axes[1].set_title('Cell Size vs 特徵維度')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n觀察：\")\n",
    "print(\"- 較小的 cell size 產生更多特徵，捕捉更細節的資訊\")\n",
    "print(\"- 但可能導致過擬合或計算量增加\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 總結\n",
    "\n",
    "### 本 Notebook 涵蓋的內容\n",
    "\n",
    "1. **完整 Pipeline**：\n",
    "   - HOG 特徵擷取\n",
    "   - SVM 分類\n",
    "   - 訓練/測試分割\n",
    "\n",
    "2. **模型評估**：\n",
    "   - 準確率\n",
    "   - 混淆矩陣\n",
    "   - Precision, Recall, F1\n",
    "\n",
    "3. **參數調整**：\n",
    "   - SVM C 參數\n",
    "   - HOG cell size\n",
    "\n",
    "### 關鍵要點\n",
    "\n",
    "1. **特徵工程很重要**：HOG 特徵的設計直接影響分類效果\n",
    "2. **模型選擇**：SVM 適合高維特徵，因為它關注 margin 而非密度\n",
    "3. **評估方法**：不只看準確率，要看混淆矩陣了解各類別表現\n",
    "\n",
    "### Module 4 完成！\n",
    "\n",
    "恭喜你完成了 Module 4 的所有內容！你已經學會：\n",
    "\n",
    "- Linear Regression（閉式解和梯度下降）\n",
    "- Logistic Regression（二分類）\n",
    "- Softmax Regression（多分類）\n",
    "- SVM（Hinge Loss）\n",
    "- K-Means（聚類）\n",
    "- GMM + EM（進階）\n",
    "- HOG + SVM（專案整合）\n",
    "\n",
    "### 下一步\n",
    "\n",
    "在 **Module 5** 中，我們將學習如何從零實作 CNN！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d20d13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 練習題\n",
    "\n",
    "### 練習 1：實作 Cross-Validation\n",
    "\n",
    "交叉驗證是評估模型泛化能力的重要方法。\n",
    "\n",
    "**任務**：實作 K-Fold Cross-Validation\n",
    "\n",
    "**提示**：\n",
    "1. 將資料分成 K 份\n",
    "2. 輪流用 K-1 份訓練，1 份驗證\n",
    "3. 返回平均準確率"
   ]
  },
  {
   "cell_type": "code",
   "id": "23d87c5f",
   "metadata": {},
   "source": [
    "# 練習 1 解答：K-Fold Cross-Validation\n",
    "\n",
    "def k_fold_cross_validation(X, y, n_classes, k=5, **kwargs):\n",
    "    \"\"\"\n",
    "    K-Fold 交叉驗證\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (N, H, W)\n",
    "        圖像資料\n",
    "    y : np.ndarray, shape (N,)\n",
    "        標籤\n",
    "    n_classes : int\n",
    "        類別數\n",
    "    k : int\n",
    "        折數\n",
    "    **kwargs : dict\n",
    "        傳給分類器的參數\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scores : list\n",
    "        每一折的準確率\n",
    "    mean_score : float\n",
    "        平均準確率\n",
    "    std_score : float\n",
    "        標準差\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    indices = np.arange(N)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    fold_size = N // k\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        # 分割驗證集和訓練集\n",
    "        val_start = i * fold_size\n",
    "        val_end = val_start + fold_size if i < k - 1 else N\n",
    "        \n",
    "        val_idx = indices[val_start:val_end]\n",
    "        train_idx = np.concatenate([indices[:val_start], indices[val_end:]])\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # 訓練模型\n",
    "        clf = HOGSVMClassifier(n_classes=n_classes, **kwargs)\n",
    "        clf.fit(X_train, y_train, lr=0.0001, n_iter=1000, verbose=False)\n",
    "        \n",
    "        # 評估\n",
    "        score = clf.score(X_val, y_val)\n",
    "        scores.append(score)\n",
    "        \n",
    "        print(f\"Fold {i+1}/{k}: Accuracy = {score:.4f}\")\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    \n",
    "    return scores, mean_score, std_score\n",
    "\n",
    "\n",
    "# 測試 5-Fold CV\n",
    "print(\"=== 5-Fold Cross-Validation ===\")\n",
    "scores, mean_acc, std_acc = k_fold_cross_validation(\n",
    "    X_images, y_labels, n_classes=4, k=5, \n",
    "    hog_cell_size=8, svm_C=10.0\n",
    ")\n",
    "\n",
    "print(f\"\\n平均準確率: {mean_acc:.4f} ± {std_acc:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c01f600d",
   "metadata": {},
   "source": [
    "### 練習 2：Grid Search 參數搜尋\n",
    "\n",
    "自動搜尋最佳參數組合。\n",
    "\n",
    "**任務**：實作簡單的 Grid Search，同時搜尋 SVM C 和 HOG cell_size"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d094c1b",
   "metadata": {},
   "source": [
    "# 練習 2 解答：Grid Search\n",
    "\n",
    "def grid_search(X_train, y_train, X_val, y_val, n_classes, param_grid):\n",
    "    \"\"\"\n",
    "    Grid Search 參數搜尋\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    param_grid : dict\n",
    "        參數網格，例如 {'svm_C': [1, 10], 'hog_cell_size': [4, 8]}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_params : dict\n",
    "        最佳參數\n",
    "    best_score : float\n",
    "        最佳分數\n",
    "    results : list\n",
    "        所有結果\n",
    "    \"\"\"\n",
    "    from itertools import product\n",
    "    \n",
    "    # 生成所有參數組合\n",
    "    keys = list(param_grid.keys())\n",
    "    values = list(param_grid.values())\n",
    "    combinations = list(product(*values))\n",
    "    \n",
    "    results = []\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    \n",
    "    print(f\"共 {len(combinations)} 種參數組合\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for combo in combinations:\n",
    "        params = dict(zip(keys, combo))\n",
    "        \n",
    "        # 訓練\n",
    "        clf = HOGSVMClassifier(n_classes=n_classes, **params)\n",
    "        clf.fit(X_train, y_train, lr=0.0001, n_iter=1000, verbose=False)\n",
    "        \n",
    "        # 評估\n",
    "        val_score = clf.score(X_val, y_val)\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        \n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'train_score': train_score,\n",
    "            'val_score': val_score\n",
    "        })\n",
    "        \n",
    "        print(f\"{params} -> Train: {train_score:.4f}, Val: {val_score:.4f}\")\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_params = params\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"最佳參數: {best_params}\")\n",
    "    print(f\"最佳驗證分數: {best_score:.4f}\")\n",
    "    \n",
    "    return best_params, best_score, results\n",
    "\n",
    "\n",
    "# 執行 Grid Search\n",
    "print(\"=== Grid Search ===\")\n",
    "\n",
    "# 分割訓練/驗證集\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_ratio=0.2, seed=123)\n",
    "\n",
    "param_grid = {\n",
    "    'svm_C': [1.0, 10.0, 100.0],\n",
    "    'hog_cell_size': [4, 8]\n",
    "}\n",
    "\n",
    "best_params, best_score, all_results = grid_search(\n",
    "    X_tr, y_tr, X_val, y_val, n_classes=4, param_grid=param_grid\n",
    ")\n",
    "\n",
    "# 用最佳參數在測試集上評估\n",
    "print(\"\\n用最佳參數訓練最終模型...\")\n",
    "final_clf = HOGSVMClassifier(n_classes=4, **best_params)\n",
    "final_clf.fit(X_train, y_train, lr=0.0001, n_iter=1500, verbose=False)\n",
    "test_score = final_clf.score(X_test, y_test)\n",
    "print(f\"測試集準確率: {test_score:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0fe40446",
   "metadata": {},
   "source": [
    "### 練習 3：Data Augmentation\n",
    "\n",
    "資料增強可以增加訓練資料的多樣性，提高模型泛化能力。\n",
    "\n",
    "**任務**：實作簡單的資料增強（旋轉、翻轉）並觀察效果"
   ]
  },
  {
   "cell_type": "code",
   "id": "2936a57a",
   "metadata": {},
   "source": [
    "# 練習 3 解答：Data Augmentation\n",
    "\n",
    "def rotate_90(image):\n",
    "    \"\"\"旋轉 90 度\"\"\"\n",
    "    return np.rot90(image)\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    \"\"\"水平翻轉\"\"\"\n",
    "    return image[:, ::-1]\n",
    "\n",
    "def vertical_flip(image):\n",
    "    \"\"\"垂直翻轉\"\"\"\n",
    "    return image[::-1, :]\n",
    "\n",
    "def augment_dataset(X, y, augment_funcs):\n",
    "    \"\"\"\n",
    "    對資料集進行增強\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (N, H, W)\n",
    "    y : np.ndarray, shape (N,)\n",
    "    augment_funcs : list of callable\n",
    "        增強函數列表\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_aug : np.ndarray\n",
    "        增強後的資料（包含原始資料）\n",
    "    y_aug : np.ndarray\n",
    "        對應的標籤\n",
    "    \"\"\"\n",
    "    X_list = [X]  # 包含原始資料\n",
    "    y_list = [y]\n",
    "    \n",
    "    for func in augment_funcs:\n",
    "        X_transformed = np.array([func(img) for img in X])\n",
    "        X_list.append(X_transformed)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_aug = np.concatenate(X_list, axis=0)\n",
    "    y_aug = np.concatenate(y_list, axis=0)\n",
    "    \n",
    "    # 打亂\n",
    "    idx = np.random.permutation(len(y_aug))\n",
    "    \n",
    "    return X_aug[idx], y_aug[idx]\n",
    "\n",
    "\n",
    "# 測試資料增強效果\n",
    "print(\"=== Data Augmentation 實驗 ===\")\n",
    "\n",
    "# 原始資料訓練\n",
    "print(\"\\n1. 不使用資料增強:\")\n",
    "clf_no_aug = HOGSVMClassifier(n_classes=4, hog_cell_size=8, svm_C=10.0)\n",
    "clf_no_aug.fit(X_train, y_train, lr=0.0001, n_iter=1000, verbose=False)\n",
    "score_no_aug = clf_no_aug.score(X_test, y_test)\n",
    "print(f\"   訓練集大小: {len(X_train)}\")\n",
    "print(f\"   測試準確率: {score_no_aug:.4f}\")\n",
    "\n",
    "# 使用資料增強\n",
    "print(\"\\n2. 使用資料增強 (翻轉):\")\n",
    "X_train_aug, y_train_aug = augment_dataset(\n",
    "    X_train, y_train, \n",
    "    [horizontal_flip, vertical_flip]\n",
    ")\n",
    "\n",
    "clf_aug = HOGSVMClassifier(n_classes=4, hog_cell_size=8, svm_C=10.0)\n",
    "clf_aug.fit(X_train_aug, y_train_aug, lr=0.0001, n_iter=1000, verbose=False)\n",
    "score_aug = clf_aug.score(X_test, y_test)\n",
    "print(f\"   訓練集大小: {len(X_train_aug)} (原本的 3 倍)\")\n",
    "print(f\"   測試準確率: {score_aug:.4f}\")\n",
    "\n",
    "print(f\"\\n準確率變化: {score_no_aug:.4f} -> {score_aug:.4f} ({(score_aug-score_no_aug)*100:+.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "767ca0e8",
   "metadata": {},
   "source": [
    "# 視覺化增強效果\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "\n",
    "# 選一個樣本展示\n",
    "sample_img = X_train[0]\n",
    "\n",
    "augments = [\n",
    "    ('Original', lambda x: x),\n",
    "    ('Horizontal Flip', horizontal_flip),\n",
    "    ('Vertical Flip', vertical_flip),\n",
    "    ('Rotate 90°', rotate_90)\n",
    "]\n",
    "\n",
    "for row, class_idx in enumerate(range(4)):\n",
    "    sample = X_train[y_train == class_idx][0]\n",
    "    \n",
    "    for col, (name, func) in enumerate(augments):\n",
    "        axes[row, col].imshow(func(sample), cmap='gray')\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(name)\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(class_names[class_idx])\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n觀察：\")\n",
    "print(\"- 資料增強可以增加訓練資料的多樣性\")\n",
    "print(\"- 但要注意增強方式要符合實際應用場景\")\n",
    "print(\"- 例如：對於形狀分類，旋轉可能改變類別（正方形 vs 菱形）\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}