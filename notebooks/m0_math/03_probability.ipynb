{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 0.3: 機率基礎\n",
    "\n",
    "這個 notebook 會教你機器學習需要的機率知識。\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "1. 理解機率的基本概念\n",
    "2. 期望值和變異數\n",
    "3. Gaussian 分布的性質\n",
    "4. Bayes' Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: 機率分布\n",
    "\n",
    "### 離散 vs 連續\n",
    "\n",
    "**離散隨機變數**：只能取特定的值（如擲骰子：1, 2, 3, 4, 5, 6）\n",
    "- 用 **PMF (Probability Mass Function)** 描述\n",
    "- $P(X = x)$ 是機率\n",
    "\n",
    "**連續隨機變數**：可以取任意實數值（如身高、溫度）\n",
    "- 用 **PDF (Probability Density Function)** 描述\n",
    "- $P(a \\leq X \\leq b) = \\int_a^b f(x) dx$\n",
    "\n",
    "### 為什麼 ML 要學機率？\n",
    "\n",
    "1. **不確定性建模**：我們的預測有多「確定」？\n",
    "2. **損失函數**：Cross-entropy loss 來自機率論\n",
    "3. **生成模型**：VAE, GAN 等需要機率基礎\n",
    "4. **貝葉斯方法**：Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例：離散分布 - 擲骰子\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "probabilities = [1/6] * 6  # 公平骰子\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(outcomes, probabilities, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Outcome')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('離散分布：公平骰子的 PMF')\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "# 範例：連續分布 - Gaussian\n",
    "plt.subplot(1, 2, 2)\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf = stats.norm.pdf(x, loc=0, scale=1)  # 標準常態分布\n",
    "plt.plot(x, pdf, 'b-', linewidth=2)\n",
    "plt.fill_between(x, pdf, alpha=0.3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('連續分布：標準常態分布的 PDF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: 期望值和變異數\n",
    "\n",
    "### 期望值 (Expectation)\n",
    "\n",
    "「平均值」的推廣：\n",
    "\n",
    "$$E[X] = \\sum_x x \\cdot P(X=x) \\quad \\text{(離散)}$$\n",
    "$$E[X] = \\int x \\cdot f(x) dx \\quad \\text{(連續)}$$\n",
    "\n",
    "### 變異數 (Variance)\n",
    "\n",
    "「分散程度」的度量：\n",
    "\n",
    "$$Var(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$\n",
    "\n",
    "**標準差** $\\sigma = \\sqrt{Var(X)}$\n",
    "\n",
    "### 為什麼重要？\n",
    "\n",
    "- **MSE Loss** = $E[(y - \\hat{y})^2]$\n",
    "- **Batch Normalization** 需要計算 mean 和 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(x):\n",
    "    \"\"\"\n",
    "    計算樣本平均值\n",
    "    \n",
    "    E[X] ≈ (1/N) Σ xᵢ\n",
    "    \"\"\"\n",
    "    # 解答：\n",
    "    return np.sum(x) / len(x)\n",
    "\n",
    "\n",
    "def compute_variance(x):\n",
    "    \"\"\"\n",
    "    計算樣本變異數\n",
    "    \n",
    "    Var(X) ≈ (1/N) Σ (xᵢ - μ)²\n",
    "    \"\"\"\n",
    "    # 解答：\n",
    "    mean = compute_mean(x)\n",
    "    return np.sum((x - mean) ** 2) / len(x)\n",
    "\n",
    "\n",
    "def compute_std(x):\n",
    "    \"\"\"計算標準差\"\"\"\n",
    "    return np.sqrt(compute_variance(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "np.random.seed(42)\n",
    "data = np.random.randn(1000)  # 1000 個標準常態樣本\n",
    "\n",
    "print(f\"我們的 mean: {compute_mean(data):.4f}\")\n",
    "print(f\"numpy mean:  {np.mean(data):.4f}\")\n",
    "print()\n",
    "print(f\"我們的 var:  {compute_variance(data):.4f}\")\n",
    "print(f\"numpy var:   {np.var(data):.4f}\")\n",
    "print()\n",
    "print(f\"我們的 std:  {compute_std(data):.4f}\")\n",
    "print(f\"numpy std:   {np.std(data):.4f}\")\n",
    "\n",
    "print(\"\\n✓ 驗證：\")\n",
    "assert np.isclose(compute_mean(data), np.mean(data))\n",
    "assert np.isclose(compute_variance(data), np.var(data))\n",
    "print(\"所有測試通過！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Gaussian 分布（超重要！）\n",
    "\n",
    "也叫「常態分布」或「高斯分布」，是 ML 中最常見的分布。\n",
    "\n",
    "### 一維 Gaussian\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "- $\\mu$：平均值（中心位置）\n",
    "- $\\sigma$：標準差（寬度）\n",
    "\n",
    "### 為什麼 Gaussian 這麼常用？\n",
    "\n",
    "1. **中央極限定理**：很多獨立隨機變數的和趨近 Gaussian\n",
    "2. **最大熵原理**：在已知 mean 和 variance 時，Gaussian 是最「不確定」的分布\n",
    "3. **數學方便**：很多計算有封閉解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    計算 Gaussian PDF\n",
    "    \n",
    "    f(x) = (1 / √(2πσ²)) × exp(-(x-μ)² / (2σ²))\n",
    "    \"\"\"\n",
    "    # 解答：\n",
    "    coef = 1 / np.sqrt(2 * np.pi * sigma**2)\n",
    "    exponent = -((x - mu)**2) / (2 * sigma**2)\n",
    "    return coef * np.exp(exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化不同參數的 Gaussian\n",
    "x = np.linspace(-6, 6, 1000)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 不同的 mean\n",
    "plt.subplot(1, 2, 1)\n",
    "for mu in [-2, 0, 2]:\n",
    "    y = gaussian_pdf(x, mu, 1)\n",
    "    plt.plot(x, y, label=f'μ={mu}, σ=1')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('改變 μ（平均值）')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 不同的 std\n",
    "plt.subplot(1, 2, 2)\n",
    "for sigma in [0.5, 1, 2]:\n",
    "    y = gaussian_pdf(x, 0, sigma)\n",
    "    plt.plot(x, y, label=f'μ=0, σ={sigma}')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('改變 σ（標準差）')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證我們的 Gaussian PDF\n",
    "x_test = np.array([0, 1, -1, 2])\n",
    "mu, sigma = 0, 1\n",
    "\n",
    "our_result = gaussian_pdf(x_test, mu, sigma)\n",
    "scipy_result = stats.norm.pdf(x_test, mu, sigma)\n",
    "\n",
    "print(\"比較我們的實作和 scipy:\")\n",
    "print(f\"Our:   {our_result}\")\n",
    "print(f\"Scipy: {scipy_result}\")\n",
    "print(f\"\\n✓ Match: {np.allclose(our_result, scipy_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多維 Gaussian\n",
    "\n",
    "$$f(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^T \\Sigma^{-1} (\\mathbf{x}-\\boldsymbol{\\mu})\\right)$$\n",
    "\n",
    "- $\\boldsymbol{\\mu}$：平均向量\n",
    "- $\\Sigma$：共變異矩陣 (covariance matrix)\n",
    "\n",
    "**直覺**：共變異矩陣決定了「橢圓」的形狀和方向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 2D Gaussian\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# 不同的 covariance matrix\n",
    "covariances = [\n",
    "    np.array([[1, 0], [0, 1]]),      # 圓形\n",
    "    np.array([[2, 0], [0, 0.5]]),    # 橢圓（沿軸）\n",
    "    np.array([[1, 0.8], [0.8, 1]]),  # 橢圓（旋轉）\n",
    "]\n",
    "titles = ['獨立、相同變異', '獨立、不同變異', '相關']\n",
    "\n",
    "x = np.linspace(-3, 3, 100)\n",
    "y = np.linspace(-3, 3, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "pos = np.dstack((X, Y))\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, (cov, title) in enumerate(zip(covariances, titles)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    rv = multivariate_normal([0, 0], cov)\n",
    "    Z = rv.pdf(pos)\n",
    "    plt.contour(X, Y, Z, levels=10)\n",
    "    plt.title(f'{title}\\nΣ = {cov.tolist()}')\n",
    "    plt.xlabel('x₁')\n",
    "    plt.ylabel('x₂')\n",
    "    plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Bayes' Theorem\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "### 術語\n",
    "\n",
    "- $P(A)$：**Prior（先驗）** - 看到 B 之前對 A 的信念\n",
    "- $P(B|A)$：**Likelihood（似然）** - 如果 A 為真，看到 B 的機率\n",
    "- $P(A|B)$：**Posterior（後驗）** - 看到 B 之後對 A 的更新信念\n",
    "\n",
    "### 直覺\n",
    "\n",
    "$$\\text{後驗} \\propto \\text{似然} \\times \\text{先驗}$$\n",
    "\n",
    "「根據新證據更新我們的信念」\n",
    "\n",
    "### 在 ML 中的應用\n",
    "\n",
    "- **Naive Bayes 分類器**\n",
    "- **Bayesian Neural Networks**\n",
    "- **最大後驗估計 (MAP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 經典範例：醫學檢測\n",
    "# \n",
    "# 一種罕見疾病，發病率 1%\n",
    "# 檢測準確率：有病檢測為陽性 99%，沒病檢測為陰性 99%\n",
    "# 問：檢測陽性，實際有病的機率？\n",
    "\n",
    "# 先驗\n",
    "P_disease = 0.01  # P(D) = 1%\n",
    "P_no_disease = 0.99  # P(¬D) = 99%\n",
    "\n",
    "# 似然\n",
    "P_positive_given_disease = 0.99  # P(+|D) = 99%\n",
    "P_positive_given_no_disease = 0.01  # P(+|¬D) = 1% (假陽性)\n",
    "\n",
    "# 全機率公式：P(+)\n",
    "P_positive = P_positive_given_disease * P_disease + P_positive_given_no_disease * P_no_disease\n",
    "\n",
    "# Bayes' theorem: P(D|+)\n",
    "P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"醫學檢測的 Bayes' Theorem 範例\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n疾病發病率 P(D) = {P_disease:.2%}\")\n",
    "print(f\"檢測敏感度 P(+|D) = {P_positive_given_disease:.2%}\")\n",
    "print(f\"假陽性率 P(+|¬D) = {P_positive_given_no_disease:.2%}\")\n",
    "print(f\"\\n陽性機率 P(+) = {P_positive:.4f}\")\n",
    "print(f\"\\n>>> 檢測陽性時，實際有病的機率 P(D|+) = {P_disease_given_positive:.2%} <<<\")\n",
    "print(\"\\n驚訝嗎？即使檢測很準確，因為疾病很罕見，\")\n",
    "print(\"大部分陽性結果仍然是假陽性！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習：實作 Naive Bayes 分類器的核心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(x, class_priors, class_means, class_stds):\n",
    "    \"\"\"\n",
    "    Naive Bayes 分類（假設特徵是獨立的 Gaussian）\n",
    "    \n",
    "    對每個類別 c，計算：\n",
    "    P(c|x) ∝ P(c) × Π P(xᵢ|c)\n",
    "    \n",
    "    取 log 避免數值問題：\n",
    "    log P(c|x) ∝ log P(c) + Σ log P(xᵢ|c)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray, shape (n_features,)\n",
    "        要分類的樣本\n",
    "    class_priors : list of float\n",
    "        每個類別的先驗機率 P(c)\n",
    "    class_means : list of np.ndarray\n",
    "        每個類別的特徵平均值\n",
    "    class_stds : list of np.ndarray\n",
    "        每個類別的特徵標準差\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predicted_class : int\n",
    "        預測的類別\n",
    "    log_probs : np.ndarray\n",
    "        每個類別的 log 機率（未正規化）\n",
    "    \"\"\"\n",
    "    n_classes = len(class_priors)\n",
    "    log_probs = np.zeros(n_classes)\n",
    "    \n",
    "    # 解答：\n",
    "    for c in range(n_classes):\n",
    "        # log P(c)\n",
    "        log_probs[c] = np.log(class_priors[c])\n",
    "        \n",
    "        # 加上 Σ log P(xᵢ|c)\n",
    "        # P(xᵢ|c) 是 Gaussian\n",
    "        for i in range(len(x)):\n",
    "            mu = class_means[c][i]\n",
    "            sigma = class_stds[c][i]\n",
    "            # log of Gaussian PDF\n",
    "            log_probs[c] += -0.5 * np.log(2 * np.pi * sigma**2)\n",
    "            log_probs[c] += -0.5 * ((x[i] - mu) / sigma)**2\n",
    "    \n",
    "    predicted_class = np.argmax(log_probs)\n",
    "    return predicted_class, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試 Naive Bayes\n",
    "# 假設有兩個類別，每個類別有 2 個特徵\n",
    "\n",
    "class_priors = [0.5, 0.5]  # 相等的先驗\n",
    "class_means = [\n",
    "    np.array([0, 0]),  # 類別 0 的特徵平均\n",
    "    np.array([2, 2]),  # 類別 1 的特徵平均\n",
    "]\n",
    "class_stds = [\n",
    "    np.array([1, 1]),  # 類別 0 的特徵標準差\n",
    "    np.array([1, 1]),  # 類別 1 的特徵標準差\n",
    "]\n",
    "\n",
    "# 測試幾個點\n",
    "test_points = [\n",
    "    np.array([0, 0]),   # 應該分到類別 0\n",
    "    np.array([2, 2]),   # 應該分到類別 1\n",
    "    np.array([1, 1]),   # 邊界附近\n",
    "]\n",
    "\n",
    "print(\"Naive Bayes 分類結果：\")\n",
    "for x in test_points:\n",
    "    pred, log_probs = naive_bayes_predict(x, class_priors, class_means, class_stds)\n",
    "    # 轉換成機率\n",
    "    probs = np.exp(log_probs - np.max(log_probs))  # 避免溢出\n",
    "    probs = probs / np.sum(probs)\n",
    "    print(f\"x = {x} → 類別 {pred}，機率 = {probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "這個 notebook 你學到了：\n",
    "\n",
    "1. **機率分布**：PMF（離散）vs PDF（連續）\n",
    "2. **期望值和變異數**：描述分布的「中心」和「分散程度」\n",
    "3. **Gaussian 分布**：ML 中最常見的分布，由 μ 和 σ 決定\n",
    "4. **Bayes' Theorem**：用新證據更新信念\n",
    "\n",
    "### 這些概念在 ML 中的應用：\n",
    "\n",
    "| 概念 | 應用 |\n",
    "|------|------|\n",
    "| 期望值 | Loss function 的定義 |\n",
    "| 變異數 | Batch Normalization |\n",
    "| Gaussian | 初始化、假設、VAE |\n",
    "| Bayes | Naive Bayes、Bayesian 方法 |\n",
    "\n",
    "---\n",
    "\n",
    "**下一個 notebook**: `04_gradient_descent.ipynb` - 梯度下降實作"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
